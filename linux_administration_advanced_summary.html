<!DOCTYPE html>
<html>
   <meta charset="UTF-8">
    <meta name="viewport"
     content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <title>Linux Advanced Administration Summary <!-- ignore --></title>
<head>
<script type=module src=/IT_notes/map_v1.js></script>
<link rel='stylesheet' type='text/css' href='/IT_notes/map_v1.css' />
</head>

<body>

    <div groupv>
<pre zoom>
<span xsmall>Central Authentication</span>
@[https://www.freeipa.org/page/Main_Page]
- Manage Linux users and client hosts in your realm from one central location
  with CLI, Web UI or RPC access. Enable Single Sign On authentication for all
  your systems, services and applications.
- Policy
- Define Kerberos authentication and authorization policies for your
  identities. Control services like DNS, SUDO, SELinux or autofs.
- Trusts
- Create mutual trust with other Identity Management systems like Microsoft
  Active Directory.
</pre>

<pre zoom>
<span xsmall>SystemD Timers</span>
<span xsmall>(Cron alt)</span>
@[https://www.maketecheasier.com/use-systemd-timers-as-cron-replacement/]
</a>
</pre>

<pre zoom TODO>
<span xsmall TODO>KVM/Qemu</span>
@[https://www.linux-kvm.org/]
- Working with Virtual Machines
  - Managing Libvirt and KVM
  - Installing a Virtual Machine
  - Using virsh
  - Using virt-manager
  - Understanding KVM Networking
  - Managing KVM Networking
  - Importing OVF Virtual Machine Files
- <span xsmall>KVM live migration</span>
@[https://www.linux-kvm.org/page/Migration]
</pre>

<pre zoom labels="backups">
<span xsmall>KVM</span>
<span xsmall>weekly</span>
<span xsmall>backup</span>
WARN: maybe oudated.
KVM weekly backup, the easy way
For the joy of all my readers here it comes the master-of-the-universe weekly script backup for KVM:

# Redirect stdout/stderr to custom log.

exec 1˃˃ /var/log/custom_$(basename ${0}).$(whoami).$(date '+%Y%m%d').log 2˃⅋1
pushd /media/backup/MyServer1/
# Keep copies of the VM for the last 4 weeks.
mv kvm.qemu.gz.1 kvm.qemu.gz.2
mv kvm.qemu.gz.0 kvm.qemu.gz.1
mv kvm.qemu.gz kvm.qemu.gz.0

# Stop KVM instance through telnet.
# KVM has to be started with the option:
# -monitor telnet:127.0.0.1:9942,server,nowait
echo "stop" | nc -q 10 127.0.0.1 9942 # Freeze KVM instance

#Here we do the real backup of the KVM instance
cat /VM_Images/kvm.qemu | gzip ˃ /media/backup/MyServer1/kvm.qemu.gz
if [ $? != 0 ]; then
echo "WARN: KVM backup failed"
fi
echo "c" | nc -q 10 127.0.0.1 9942 # Continue KVM instance
popd

For the previous script to work correctly we have to start the KVM instance with the option -monitor telnet:127.0.0.1:9942.

In my particular system I start KVM instances at startup in /etc/rc.local. This is script is also quite interesting so I extracted all the kvm related stuff:

/etc/rc.local:
# Setting up the bridge (tip: apt-get install bridge-utils)
brctl addbr ofi1
brctl addif ofi1 eth1
ifconfig eth1 0.0.0.0 promisc up
ifconfig ofi1 192.168.2.100 netmask 255.255.0.0 up
ifconfig ofi1:1 172.16.1.3

...
kvm -net nic,macaddr=52:54:00:19:34:56 \
-net tap,script=/etc/qemu-ifup -hda /VM-Images/kvm.qemu \
-boot c -vnc :5 1˃/var/log/custom_kvm.qemu.log \
-monitor telnet:127.0.0.1:9942,server,nowait 2˃⅋1 ⅋
...
# ionice/renice down our virtual machine
PID=$(sof /VM-Images/kvm.qemu | grep -v ^COMMAND | while read cmd pid staff; do echo $pid; done)
ionice -c 3 -p ${PID} ⅋
renice 10 -p ${PID} ⅋

/etc/qemu-ifup:
#!/bin/sh
# ofi1 is the choosen name in /etc/rc.local
/usr/sbin/brctl addif ofi1 $1 ;
ifconfig $1 0.0.0.0 up;
</pre>

<pre zoom>
<span xsmall TODO>Spice</span>
<span xsmall>(Virt.Desktops)</span>
@[http://fedoraproject.org/wiki/Features/Spice]
- Spice aims to provide a complete open source solution
  for interaction with virtualized desktops
</pre>

<span title>Storage</span>
<pre zoom>
<span xsmall>REF:Alpine Persistence</span>
<span xsmall>Storage Summit</span>
@[https://alpss.at/]
08:30 - 09:00   Zoned Namespaces for NVMe   Matias Bjørling and Christoph Hellwig
10:00 - 10:30   Copy Offload    Bart van Assche
10:30 - 11:00   PCI 2P2 and computational storage   Stephen Bates
11:00 - 11:30   Exciting new stuff in RDMA  Idan Burstein
12:00 - 12:30   SPI-attached Flash Memory   Boris Brezillon and Miquel Raynal
12:30 - 13:00   Advanced power-cut testing the MTD stack    Richard Weinberger
14:00 - 19:00   BOFs and hallway track (or hiking on your own)
08:30 - 09:00   Qemu as a Memory emulation platform Damien Le Moal
09:00 - 09:30   UMAP    Adam Manzanares
10:00 - 10:30   Inode namespacing – COW inodes  Jeff Mahoney
10:30 - 11:00   Adding filesystem authentication to UBIFS   David Gstir
11:00 - 11:30   Reverse Engineering APFS (Apple File System)    Johannes Thumshirn
09:00 - 09:30   Blk-mq and zoned devices    Bart van Assche and Damien Le Moal
12:00 - 13:00   Blk-mq: timeout handling, power management, etc Bart van Assche
</pre>
<pre zoom>
<span xsmall>block multi-queue</span>
- kernel 3.13+
- block layer "blk-mq" introduces block multi-queue support,
  intended to meet the high IOPS requirements of SSDs:
  Cite (Jens Axobe):
  """the classic request_fn based driver doesn't work well enough
  (for big IOPS)
  Axboe The design is centered around per-cpu queues for queueing IO,
  which then funnel down into x number of hardware submission queues
</pre>


<pre zoom bgorange>
<span xsmall>sharedroot</span>
@[http://fedoraproject.org/wiki/Features/Opensharedroot]
The open sharedroot project provides abilities to boot multiple linux systems
with the same root filesystem providing a single system filesystem based
cluster. (NFS, GFS,...)
</pre>

<pre zoom>
<span xsmall TODO>Loop device</span>
</pre>

<pre zoom>
<span xsmall>debugfs</span>
@[https://linux.die.net/man/8/debugfs]
- ext2/ext3/ext4 file system debugger

- It can be used to examine and change
  the state of an ext2, ext3, or ext4 file system.
</pre>

<pre zoom TODO labels="storage,security">
<span xsmall>File Integrity Monitoring at scale</span>
(RSA Conf)
    https://www.rsaconference.com/writable/presentations/file_upload/csv-r14-fim-and-system-call-auditing-at-scale-in-a-large-container-deployment.pdf
</pre>

<pre zoom labels="">
<span xsmall>Hard.Storage</span>
@[https://www.thomas-krenn.com/en/wiki/Category:Storage]
</pre>

</div>

<div groupv>
<span title>Kernel</span>

<pre zoom>
<span xsmall>/proc/meminfo</span>
$ cat /proc/meminfo
MemTotal:       16116792 kB
MemFree:         2042420 kB
MemAvailable:   10656344 kB
Buffers:         1637424 kB
Cached:          6513208 kB
SwapCached:          352 kB
Active:          8372356 kB
Inactive:        3940908 kB
Active(anon):    3755128 kB
Inactive(anon):   645496 kB
Active(file):    4617228 kB
Inactive(file):  3295412 kB
Unevictable:           0 kB
Mlocked:               0 kB
SwapTotal:       8126460 kB
SwapFree:        8124156 kB
Dirty:              1304 kB
Writeback:             0 kB
AnonPages:       4162388 kB
Mapped:           732652 kB
Shmem:            238000 kB
Slab:            1337700 kB
SReclaimable:    1029376 kB
SUnreclaim:       308324 kB
KernelStack:       15632 kB
PageTables:        31724 kB
NFS_Unstable:          0 kB
Bounce:                0 kB
WritebackTmp:          0 kB
CommitLimit:    16184856 kB
Committed_AS:   11012532 kB
VmallocTotal:   34359738367 kB
VmallocUsed:           0 kB
VmallocChunk:          0 kB
HardwareCorrupted:     0 kB
AnonHugePages:         0 kB
ShmemHugePages:        0 kB
ShmemPmdMapped:        0 kB
CmaTotal:              0 kB
CmaFree:               0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:               0 kB
DirectMap4k:     1147072 kB
DirectMap2M:    15319040 kB
</pre>

<pre zoom>
<span xsmall TODO>ELF</span>
@[https://en.wikipedia.org/wiki/Executable_and_Linkable_Format]
- man readelf
</pre>

<pre zoom labels="">
<span xsmall>Shared Lib</span>
<span xsmall>management</span>
Linux Commands For Shared Library Management and Debugging Problems:
@[http://www.cyberciti.biz/tips/linux-shared-library-management.html]
</pre>


<pre zoom>
<span xsmall>Ksplice</span>
@[https://en.wikipedia.org/wiki/Ksplice]
See also:
 - kexec, a method for loading a whole new kernel from a running system
 - kGraft, kpatch and KernelCare, other Linux kernel live patching
   technologies developed by SUSE, Red Hat and CloudLinux, respectively

<a TODO href="https://www.2daygeek.com/how-to-install-upgrade-unbreakable-enterprise-kernel-uek-in-oracle-linux/#">1</a>
<a TODO href="https://www.2daygeek.com/how-to-updateinstall-oracle-kernel-critical-security-updates-without-rebooting/">2</a>
<a TODO href="https://serverfault.com/questions/78406/is-ksplice-production-ready/">3</a>
</pre>

<pre zoom labels="">
<span xsmall>Attach Interrupt to CPU</span>
<span xsmall>Real-time processes</span>
@[https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_MRG/1.3/html/Realtime_Tuning_Guide/sect-Realtime_Tuning_Guide-General_System_Tuning-Interrupt_and_Process_Binding.html]
</pre>

<pre zoom>
<span xsmall>automatic NUMA balancing</span>
- automatic non-uniform memory access (NUMA) balancing, Linux 3.13+
</pre>

<pre zoom>
<span xsmall>slabtop</span>
<span xsmall>Mem Monit</span>

$ sudo slabtop

@[Ref: http://xmodulo.com/visualize-memory-usage-linux.html]
In the presence of virtual memory abstraction, accurately quantifying physical memory usage of a process is actually
not straightforward.
The virtual memory size of a process is not meaningful because it does not tell how much of it is actually allocated
 physical memory.
Resident set size (RSS), reported by top command, is one
popular metric which captures what portion of a process' reported memory is residing in RAM.  However, aggregating RSS
 of existing processes can easily overestimate the overall
physical memory usage of the Linux system because the same
physical memory page can be shared by different processes.

Proportional set size (PSS) is a more accurate measurement of
 effective memory usage of Linux processes since PSS properly
 discounts the memory page shared by more than one process.
  Unique set size (USS) of a process is a subset of the
process' PSS, which is not shared by any other processes.

The command-line tool smem can generate a variety of reports
related to memory PSS/USS usage by pulling information from
/proc.  It comes with built-in graphical chart generation
capabilities
Install:
Debian/Ubuntu:
  $ sudo apt-get install smem
Mint:
  $ sudo apt-get install smem python-matplotlib python-tk
Fedora or CentOS/RHEL:
Step 1: enable EPEL repository first.
Step 2: $ sudo yum install smem python-matplotlib

Check Memory Usage with Smem
When you run smem as a unprivileged user, it will report physical memory usage of every process launched by the current user, in an increasing order of PSS.

If you want to check the overall system memory usage for all users, run smem as the root:
$ sudo smem

To view per-user memory usage:
$ sudo smem -u
</pre>

<pre zoom labels="">
<span xsmall>Linux input ecosystem</span>
@[http://joeshaw.org/2010/10/01/681]
</pre>

<pre zoom labels="">
<span xsmall>Ftrace</span>
  Kernel monitoring/debugging
  Debugging the kernel with ftrace:1  http://lwn.net/Articles/365835/
  Debugging the kernel with ftrace:2  http://lwn.net/Articles/366796/
  Debugging the kernel with ftrace:3  http://lwn.net/Articles/370423/

 Note: ftrace is started soon after kernel start. dmesg output shows:

 $ sudo dmesg
  1 [    0.073437] smpboot: Allowing 15 CPUs, 11 hotplug CPUs
    ...
  8 [    0.073460] [mem 0xf0000000-0xfbffffff] available for PCI devices
    ...
 19 [    0.074347] Kernel command line: BOOT_IMAGE=/boot/vmlinuz-5.15.0-1022-aws root....
    ...
 22 [    0.078058] Inode-cache hash table entries: 1048576 (order: 11, 8388608 bytes, linear)
 23 [    0.078296] mem auto-init: stack:off, heap alloc:on, heap free:off
    ...
 24 [    0.148173] Memory: 16369016K/16776820K available ....
 25 [    0.148535] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=15, Nodes=1
 26 [    0.148555] Kernel/User page tables isolation: enabled
 27 [    0.148582] ftrace: allocating 50194 entries in 197 pages   <······························
 28 [    0.173428] ftrace: allocated 197 pages with 4 groups
 29 [    0.173682] rcu: Hierarchical RCU implementation.
 30 [    0.173684] rcu:     RCU restricting CPUs from NR_CPUS=8192 to nr_cpu_ids=15.
 ...


See also:
- ptrace, uditd, dTrace, OProfile or SystemTap, audtctl
- Systemtap/Dtrace/LTTng/perf Comparison:  http://sourceware.org/systemtap/wiki/SystemtapDtraceComparison
- "http://people.redhat.com/srostedt/kernelshark/HTML/:
KernelShark is a front end reader of trace-cmd(1) output. ""trace-cmd record"" and ""trace-cmd extract"" create
a trace.dat (trace-cmd.dat(5)) file. kernelshark can read this file and produce a graph and list view of its data."
</pre>

<pre zoom>
<span xsmall>SystemTap Kernel Monit</span>
@[https://sourceware.org/systemtap/]
- Eclipse SystemTap Integration
   https://help.eclipse.org/neon/index.jsp?topic=%2Forg.eclipse.linuxtools.docker.docs%2FLinux_Tools_Project%2FDocker_Tooling%2FUser_Guide%2FUser-Guide.html&cp=15_0

- https://sourceware.org/systemtap/tutorial/
- http://phoronix.com/scan.php?page=news_item&px=SystemTap-3.0-Released
https://sourceware.org/ml/systemtap/2016-q1/msg00179.html
- SystemTap, a DTrace-like means of dynamically profiling Linux with a scripting language and tool, is out with version 3.0.
    SystemTap 3.0 was announced on Sunday and it ships with experimental monitor and interactive modes,
    optimized associative arrays, function overloading, new scripting samples, scripting language changes, and more.
</pre>

<pre zoom>
<span xsmall>Monit uninterruptible(blocking) system calls</span>

- KISS script to list any process that could have trouble beeing blocked by an uninterruptible system call.

# while true; do ps -e fo stat,cmd | grep ^D ⅋⅋ echo "-------"; sleep 0.1 ; done

D˂    └─ [scsi_eh_0]
D         └─ hald─addon─storage: polling /dev/sr0 (every 2 sec)
───────
D         └─ hald─addon─storage: polling /dev/sr0 (every 2 sec)
───────
D˂    └─ [md0_raid1]
D˂    └─ [kjournald]
───────
D˂    └─ [md0_raid1]
───────
D˂    └─ [md0_raid1]
───────
D˂    └─ [md0_raid1]
The output in this case is normal [md0_raid1],kjournald and syslogd are making frequent disk writes.
</pre>


</div>

<div groupv>
<span title>Containers</span>

<pre zoom>
<span xsmall>namespace.conf</span>
- man 5 namespace.conf
Linux Namespaces:
- https://en.wikipedia.org/wiki/Linux_namespaces
- http://man7.org/linux/man-pages/man1/nsenter.1.html
@[https://lwn.net/Articles/531114/]
</pre>

<pre zoom>
<span xsmall>Cgroups</span>
</pre>

<pre zoom>
<span xsmall>Assign new IP</span>
<span xsmall>to chrooted env</span>
@[https://unix.stackexchange.com/questions/98808/how-to-assign-an-additional-ip-hostname-to-a-chrooted-environment]
</pre>

<pre zoom>
<span xsmall>Hidding processes</span>
<span xsmall>to other Users</span>
<a href="http://www.cyberciti.biz/faq/linux-hide-processes-from-other-users/">REF</a>
- The hidepid option in the procfs defines how much info
  about processes we want to be available for non-owners.

  hidepid=0 : (default old behavior), anybody may read
              all world-readable /proc/PID/* files</li>
  hidepid=1 : users may not access any /proc/ / directories,
              but their own.
              Sensitive files like cmdline, sched*, status
              are NOW protected against other users

  hidepid=2 : equals to hidepid=1 plus :
              - /proc/PID/  will be invisible to other users.
                It complicates intruder's task of gathering info
                about running processes, whether some daemon
                runs with elevated privileges, whether another user
                runs some sensitive program, whether other users run any
                program at all, etc.Linux kernel protection.

Ex:
# mount -o remount,rw,hidepid=2 /proc
Alternatively edit /etc/fstab:
proc  /proc  proc defaults,hidepid=2  0   0
</pre>
</div>

<div groupv>
<span title>Security Hardening</span>
<pre zoom>
<span xsmall>Grsecurity®</span>
@[https://grsecurity.net/]
Grsecurity: extensive security enhancement to the Linux kernel that defends
  against a wide range of security threats through intelligent access control,
  memory corruption-based exploit prevention, and a host of other system
  hardening that generally require no configuration.

   It has been actively developed and maintained for the past 17 years.
  Commercial support for grsecurity is available through Open Source Security, Inc

<a href="https://www.grsecurity.net/compare.php">Comparation grsecurity SELinux AppArmor KSPP</a>

<a href="https://en.wikipedia.org/wiki/Grsecurity#PaX">REF</a>
 """A major component bundled with grsecurity is PaX. Among other features,
the patch flags data memory, the stack, for example, as non-executable and
program memory as non-writable. The aim is to prevent memory from being
overwritten, which can help to prevent many types of security vulnerabilities,
such as buffer overflows. PaX also provides address space layout randomization
(ASLR), which randomizes important memory addresses to reduce the probability
of attacks that rely on easily predicted memory addresses."""
</pre>

<pre zoom TODO>
<span xsmall>SysDig Container Monit</span>
@[https://sysdig.com/opensource/sysdig/]

<a href="http://xmodulo.com/monitor-troubleshoot-linux-server-sysdig.html">How to monitor and troubleshoot a Linux server using sysdig</a>
Last updated on October 13, 2014 Authored by Gabriel Cánepa
What is the first thing that comes to mind when you need to track system calls made and received by a process?
You'll probably think of strace, and you are right. What tool would you use to monitor raw network traffic from the command line?
If you thought about tcpdump, you made an excellent choice again. And if you ever run into the need to having to keep track of open files
(in the Unix sense of the word: everything is a file), chances are you'll use lsof.

strace, tcpdump, and lsof are indeed great utilities that should be part of every sysadmin's toolset, and that is precisely the reason why you
will love sysdig, a powerful open source tool for system-level exploration and troubleshooting, introduced by its creators as ""strace + tcpdump + lsof + awesome
sauce with a little Lua cherry on top."" Humor aside, one of the great features of sysdig resides in its ability not only to analyze the ""live"" state of a Linux system,
but also to save the state in a dump file for offline inspection. What's more, you can customize sysdig's behavior or even enhance its capabilities by using built-in
 (or writing your own) small scripts called chisels. Individual chisels are used to analyze sysdig-captured event streams in various script-specific fashions.
"
"In this tutorial we'll explore the installation and basic usage of sysdig to perform system monitoring and troubleshooting on Linux.

Installing Sysdig
For this tutorial, we will choose to use the automatic installation process described in the official website for the sake of simplicity, brevity, and
distribution agnosticity. In the automatic process, the installation script automatically detects the operating system and installs all the necessary dependencies.

Run the following command as root to install sysdig from the official apt/yum repository:
# curl -s https://s3.amazonaws.com/download.draios.com/stable/install-sysdig | bash

Once the installation is complete, we can invoke sysdig as follows to get a feel for it:
# sysdig
Our screen will be immediately filled with all that is going on in our system, not allowing us to do much more with that information. For that reason, we will run:

# sysdig -cl | less
to see a list of available chisels. The following categories are available by default, each of which is populated by multiple built-in chisels.
CPU Usage, Errors, I/O, Logs, Misc, Net, Performance, Security, System State,
"
"
To display information (including detailed command-line usage) on a particular chisel, run:
# sysdig -cl [chisel_name]
For example, we can check information about spy_port chisel under ""Net"" category by running:
# sysdig -i spy_port

Chisels can be combined with filters (which can be applied to both live data or a trace file) to obtain more useful output.

Filters follow a ""class.field"" structure. For example:

fd.cip: client IP address.
evt.dir: event direction can be either '˃' for enter events or '˂' for exit events.
The complete filter list can be displayed with:

# sysdig -l
In the rest of the tutorial, I will demonstrate several use cases of sysdig.

Sysdig Example: Troubleshooting Server Performance
Suppose your server is experiencing performance issues (e.g., unresponsiveness or significant delays in responding). You can use the bottlenecks chisel
to display a list of the 10 slowest systems calls at the moment.

"
"Use the following command to check up on a live server in real time. The ""-c"" flag followed by a chisel name tells sysdig to run the specified chisel.

# sysdig -c bottlenecks
Alternatively, you can conduct a server performance analysis offline. In that case, you can save a complete sysdig trace to a file, and run the bottlenecks chisel against the trace as follows.

First, save a sysdig trace (use Ctrl+c to stop the collection):

# sysdig -w trace.scap
Once the trace is collected, you can check the slowest systems calls that were performed during the capture interval by running:

# sysdig -r trace.scap -c bottlenecks


You want to pay attention fo columns #2, #3, and #4, which indicate execution time, process name, and PID, respectively.

Sysdig Example: Monitoring Interactive User Activities
Suppose you as a sysadmin want to monitor interactive user activities in a system (e.g., what command a user typed from the command line,
and what directories the user went to). That is when spy_user chisel comes in handy.

Let's first collect a sysdig trace with a couple of extra options.

# sysdig -s 4096 -z -w /mnt/sysdig/$(hostname).scap.gz
""-s 4096"" tells sysdig to capture up to 4096 bytes of each event.
""-z"" (used with ""-w"") enables compression for a trace file.
""-w <trace-file>"" saves sysdig traces to a specified file.
In the above, we customize the name of the compressed trace file on a per-host basis. Remember that you can interrupt the execution of sysdig at any
moment by pressing Ctrl + c.

Once we've collected a reasonable amount of data, we can view interactive activities of every user in a system by running:

# sysdig -r /mnt/sysdig/debian.scap.gz -c spy_users


The first column in the above output indicates the PID of the process associated with a given user's activity.

What if you want to target a specific user, and monitor the user's activities only? You can filter the results of the spy_users chisel by username:

# sysdig -r /mnt/sysdig/debian.scap.gz -c spy_users ""user.name=xmodulo""


Sysdig Example: Monitoring File I/O
We can customize the output format of sysdig traces with ""-p"" flag, and indicate desired fields (e.g., user name, process name, and file or socket name)
enclosed inside double quotes. In this example, we will create a trace file that will only contain writing events in home directories (which we can inspect later with ""sysdig -r writetrace.scap.gz"").

# sysdig -p ""%user.name %proc.name %fd.name"" ""evt.type=write and fd.name contains /home/"" -z -w writetrace.scap.gz


Sysdig Example: Monitoring Network I/O
As part of server troubleshooting, you may want to snoop on network traffic, which is typically done with tcpdump. With sysdig, traffic sniffing can be done as easily, but in more user friendly fashions.

For example, you can inspect data (in ASCII) that has been exchanged with a particular IP address, served by a particular process (e.g., apache2):

# sysdig -s 4096 -A -c echo_fds fd.cip=192.168.0.100 -r /mnt/sysdig/debian.scap.gz proc.name=apache2
If you want to monitor raw data transfer (in binary) instead, replace ""-A"" with ""-X"":

# sysdig -s 4096 -X -c echo_fds fd.cip=192.168.0.100 -r /mnt/sysdig/debian.scap.gz proc.name=apache2
For more information, examples, and case studies, you can check out the project website. Believe me, the possibilities are limitless. But don't just take my word for it.
 Install sysdig and start digging today!
</pre>


<pre zoom>
<span xsmall>SysDig Falco</span>
@[https://sysdig.com/blog/selinux-seccomp-falco-technical-discussion/]
</pre>

<pre zoom>
<span xsmall bgorange>HoneyPots with</span>
<span xsmall bgorange>SysDig and Falco</span>
@[https://labs.mwrinfosecurity.com/blog/high-interaction-honeypots-with-sysdig-and-falco]
</pre>

<pre zoom labels="">
<span xsmall>practical hardening guide</span>
@[https://github.com/trimstray/the-practical-linux-hardening-guide]
</pre>


<pre zoom labels="" bgorange>
<span xsmall>Tracing Systems</span>
<span xsmall>and how they fit</span>
<span xsmall>together</span>
@[https://jvns.ca/blog/2017/07/05/linux-tracing-systems/] (Julia Evans
</pre>
</div>

<div groupv>
<span xsmall>Non-ordered</span>
<pre zoom labels="performance,tunning">
<span xsmall>DeviceKit-power</span>
<span xsmall>latency control</span>
@[https://blogs.gnome.org/hughsie/2008/11/06/devicekit-power-latency-control/]
Use cases:
    I want my IM application to request 0.5s latency for messages
    I’m running an OpenGL simulation and want maximum performance, even on battery
    I’m running an SQL server for a credit card company, and want the server to request low latency CPU and network as any delay costs money
    I’m an admin, and want to change the power consumption vs. latency from cron scripts so it uses high latency during the night for maximum power saving, and low latency during business hours.
    I want high throughput when copying files, but want low throughput for downloading updates in the background.
    I want my power manager to set all latencies to lowest when on AC power
    I don’t want my users messing with latency settings
    I’m and admin and I want to be able to override all latency settings on my machines
</pre>

<pre zoom labels="">
<span xsmall>uPower</span>
https://upower.freedesktop.org/

 UPower is an abstraction for enumerating power devices, listening to device events and querying history and statistics. Any application or service on the system can access the org.freedesktop.UPower service via the system message bus. Some operations (such as suspending the system) are restricted using PolicyKit.

UPower was once called DeviceKit-power. UPower aims to make a large chunk of HAL redundant, as HAL is officially deprecated.

UPower is also useful to control the latency of different operations on your computer, which enables you to save significant amounts of power. Nothing much uses this interface yet, but this is a classic chicken and egg scenario, and I think it's important to encourage the egg to lay a chicken. Please report any problems to the Freedesktop bugzilla or send a mail to the DeviceKit mailing list for discussion.
</pre>


<pre zoom>
<span xsmall>Monit</span>
<span xsmall>Ligthweight</span>
<span xsmall>watchdog</span>
@[https://mmonit.com/monit/]
(Service Monitoring)
- With all features needed for system monitoring and error recovery. It's like
- How to install Monit and monitor the performance of your linux server:
  https://techarena51.com/blog/how-to-install-monit-monitoring-service-on-your-linux-vps-server/
- having a watchdog with a toolbox on your server
</pre>



<pre zoom labels="performance">
<span xsmall>Timechart</span>
<span xsmall>Global System</span>
<span xsmall>performance</span>
- /proc/"PID"/*
@[http://www.linux-magazine.com/Online/News/Timechart-Zoom-in-on-Operating-System]

Intel developer Arjan van de Ven is working on a new tool named Timechart
that records Linux system performance in detailed graphics.

Van de Ven, who also worked on the energy-saving tool Powertop, wants to
enhance tools such as Oprofile, LatencyTOP and Perf with Timechart. The new
program provides graphical results, reminiscent of Bootchart, in fact going
beyond the boot process analysis tool used as its model by tying in all the
other processes on the system.
The Timechart analysis tool outputs graphics in SVG format in this release
that can put programs such as Inkscape almost literally under the microscope.

Timechart renders graphics using the SVG vector format and the developer
recommends using Inkscape to view the output, which in van de Ven's terms
makes them "infinitely zoomable." Easily identifiable graphically are, for
example, operating sytem details such as the waiting process for the
scheduler -- a contribution the Intel developer can make to the current
discussion about schedulers on the kernel mailing list.

Timechart also diagnoses the results of power management settings. The
program supports multiprocessor machines. Further details are in van de Ven's
blog entry, where he interprets some of the graphical results. The source
code is currently posted as patches on the linux-kernel mailing list. A
downloadable and installable version is not yet available because of changes
still to be made to the kernel infrastructure to make Timechart work.

Timechart developer van de Ven still has some misgivings about the program's
name and is thus looking for suggestions in his blog.
</pre>



</div>

<div groupv>
<pre title>
<a href="http://psmisc.sf.net/">psmisc</a>
</pre>
<pre zoom labels="">
<span xsmall>fuser</span>
identifies processes that are using files or sockets
</pre>
<pre zoom labels="">
<span xsmall bgorange>peekfd</span>
shows the data traveling over a file descriptor
</pre>

<pre zoom labels="performance">
<span xsmall>prtstat</span>
- prtstat: print the contents of /proc/˂pid˃/stat
º$ sudo prtstat 2192                                                  │$ sudo prtstat -r 2192º
  Process: firefox            State: S (sleeping)                     │        pid: 2192                                comm: firefox
    CPU#:  2          TTY: 4:2    Threads: 66                         │      state: S                                   ppid: 1682
  Process, Group and Session IDs                                      │       pgrp: 1362                             session: 1362
    Process ID: 2192        Parent ID: 1682                           │     tty_nr: 1026                               tpgid: 1362
      Group ID: 1362       Session ID: 1362                           │      flags: 404100                            minflt: 1724794
    T Group ID: 1362                                                  │    cminflt: 1732825                           majflt: 696
                                                                      │    cmajflt: 172                                utime: 54521
 ºPage Faultsº                                                        │      stime: 9116                              cutime: 18023
    This Process    (minor major):  1724534       696                 │     cstime: 3596                            priority: 20
    Child Processes (minor major):  1732825       172                 │       nice: 0                            num_threads: 65
  CPU Times                                                           │itrealvalue: 0                              starttime: 12236
    This Process    (user system guest blkio): 545.13  91.09 0.00 0.38│      vsize: 9464258560                           rss: 100095
    Child processes (user system guest):       180.23  35.96 0.00     │     rsslim: 18446744073709551615               startcode: 94493428105216
  Memory                                                              │    endcode: 94493428285277                startstack: 140730047695840
    Vsize:       9464 MB                                              │    kstkesp: 0                                kstkeip: 0
    RSS:         º410 MBº              RSS Limit: 18446744073709 MB   │      wchan: 0                                  nswap: 0
    Code Start:  0x55f0f7374000        Code Stop:  0x55f0f739ff5d     │     cnswap: 0                            exit_signal: 17
    Stack Start: 0x7ffe44808be0                                       │  processor: 1                            rt_priority: 0
    Stack Pointer (ESP):          0    Inst Pointer (EIP):        0   │     policy: 0                  delayaccr_blkio_ticks: 38
  Scheduling                                                          │ guest_time: 0                            cguest_time: 0
    Policy: normal
    Nice:   0          RT Priority: 0 (non RT)

TODO: Explain
</pre>
</div>

<div groupv>
<span xsmall>Non-classified</span>

<pre zoom labels="forensic,security">
<span xsmall>Dump proc.memory in real time</span>
@[http://www.forensicswiki.org/wiki/Tools%3aMemory_Imaging#Linux]
</pre>

<pre zoom labels="storage,performance">
<span xsmall>Check locked files</span>
http://www.linuxask.com/questions/how-to-check-if-a-file-is-locked-in-linux:
Suppose a file test.txt is being locked by a program, e.g. using the flock system call, how can we know if this file is really being locked?

# lsof test.txt
COMMAND  PID USER   FD   TYPE DEVICE SIZE   NODE NAME
perl    5654 john 3uW  REG    8,1    1 983057 test.txt

The W means the file is currently held by an exclusive lock. You can find more information in the link below:

http://linux.die.net/man/2/flock

<span xsmall>File locks per directory</span>

SRC: http://unix.stackexchange.com/questions/22120/how-to-trace-file-locks-per-directory
How to trace file locks (per directory):
Make sure that the auditd daemon is started, then use auditctl to configure what you want to log. For ordinary filesystem accesses, you would do:

auditctl -w /path/to/directory
auditctl -a exit,always -S fnctl -S open -S flock -F dir=/path/to/directory

The -S option can be used to restrict the logging to specific syscalls. The logs appear in /var/log/audit/audit.log on Debian, and probably on Fedora as well."
</pre>

<pre zoom labels="">
<span xsmall>A tour of the Linux Graphics Stack</span>
@[http://cworth.org/talks/lca_2009/html/lca-2009-001.html]
</pre>

<pre zoom labels="">
<span xsmall>SysRq Keyboard keys</span>
Magic SysRq key - Wikipedia http://en.wikipedia.org/wiki/Magic_SysRq_key

The magic SysRq key is a key combination understood by the Linux kernel,
which allows the user to perform various low-level commands regardless of the
system's state. It is often used to recover from freezes, or to reboot a
computer without corrupting the filesystem.[1] Its effect is similar to the
computer's hardware reset button (or power switch) but with many more options
and much more control.
</pre>

<pre zoom labels="">
<span xsmall>ConsoleKit</span>
ConsoleKit is a framework for keeping track
of the various users, sessions, and seats present
on a system. It provides a mechanism for software
to react to changes of any of these items or of
any of the metadata associated with them.
</pre>

<pre zoom labels="">
<span xsmall bgorange>open sharedroot</span>
@[http://fedoraproject.org/wiki/Features/Opensharedroot]
- allows to boot multiple linux systems with the
  same root filesystem providing a single system
  filesystem based cluster. (NFS, GFS,...)
</pre>

<pre zoom labels="backups">
<span xsmall>Data Recovery</span>
-_ Using TCT To Recover Lost Data On Linux Or Unix
http://linuxshellaccount.blogspot.com/2009/05/using-tct-to-recover-lost-data-on-linux.html
</pre>

</div>
</body>

</html>
<!--
TODO
__________________________________


________________________
https://opensourceforu.com/2013/12/things-know-futexes/
__________________________
TODO: linux bft filters kernwl 4.14+
_______________________
https://blog.packagecloud.io/eng/2016/04/05/the-definitive-guide-to-linux-system-calls/
____________________
https://www.ostechnix.com/improve-linux-systems-security-using-firejail/
__________________
https://en.wikipedia.org/wiki/Netlink
______________
https://events.static.linuxfound.org/images/stories/slides/jls09/jls09_ikeda.pdf
_______________________
https://www.phoronix.com/scan.php?page=news_item&px=Linux-5.2-Turning-On-GCC9-LP
Linux 5.2 To Enable GCC 9's Live-Patching Option, Affecting Performance In Select Cases
_____________________
https://www.reddit.com/r/linuxadmin/comments/b5pbc6/one_volume_group_vs_rootvg_appvg/
One volume group vs rootvg & appvg

I am curious what you guys prefer, I have been generally using a separate volume group for the application and OS. Maybe it is from past experience with physical hardware where we use 2 mirror drives for the OS and multiple raid5 drives for the application. For VMs I have been carrying over the processes by creating one OS disk ~60GB and one disk for the for the application that can vary based off needs. I give each a vg then create separate LVMs from there. In situations where we have something like Oracle DBs, we generally create a couple of volume groups for it and add a lot of luns to the devices from a SAN card. From there we create the required LVMs based off the DBA's requirements.


I guess this is something I really haven't thought much about, though I am curious about what you guys have done?
________________________
https://www.reddit.com/r/linuxadmin/comments/bapwd4/increase_server_speed_with_kernel_tcp_bbr/
Increase server speed with kernel TCP BBR
r/sysadmin
•
Posted byu/sammdu
2 months ago
Increase server speed with kernel TCP BBR
Linux

This CRAZY kernel feature increased the wget average of my VPS from 349KB/s to 1.47MB/s! Increase your Linux server Internet speed with TCP BBR congestion control.

https://www.cyberciti.biz/cloud-computing/increase-your-linux-server-internet-speed-with-tcp-bbr-congestion-control/

p.s. Here's a simple bash script for easy setup of TCP BBR:

https://gist.github.com/sammdu/668070b486832f47f3b0da2200a7954f
logrotate config question - rsyslog and haproxy

I have an haproxy box on Centos 7.6.1810 core that went from proof-of-concept to production in the usual way and now I have a 16G haproxy.log file. I thought I had logrotate working but I was wrong.

In my logrotate config for haproxy, I have the following:

/var/log/haproxy/haproxy.log {
        daily
        missingok
        rotate 28
        maxsize 500M
        compress
        delaycompress
        notifempty
        create 640 root root
        sharedscripts
        postrotate
        reload rsyslog >/dev/null 2>&1 || true
        endscript
}

The issue here is everything runs ok and a new haproxy.log file is created (other one is compressed and renamed) but instead of haproxy writing logs to a fresh "haproxy.log" file, I end up writing to an haproxy.log.1 file - until I restart rsyslog.

I would seem to me that "reload rsyslog >/dev/null 2>&1 || true" isn't doing anything. When I replace "reload rsyslog >/dev/null 2>&1 || true" with "systemctl restart rsyslog" everything seems to function as I'd expect. I have two questions:


*Can someone tell me exactly what this is supposed to do (I feel like I see it regularly):
_________________________
https://www.reddit.com/r/linuxadmin/comments/bcgykl/infrastructure_as_code_recommendations/

Infrastructure as Code Recommendations

Background: Windows Admin, Linux enthusiast with enough knowledge to be very dangerous (:(){ :|:& };:, anyone?)

Looking for your real-world recommendations for 'Infrastructure as Code' solutions. So far, I'm collecting information on Salt, Terraform, Chef, Ansible, and Puppet (listed alphabetically by second letter), but open to whatever people use IRL. Hit me with the good, bad, and ugly of what you're using! :D

Edit for clarity: I have no idea what I'm doing or what I'm asking :)

I'd like to start learning an IaC solution for fun, but I want to use something that could be added to my resume if I get good enough at it. At present, my job is Windows, so something that could be useful at work would be a cool perk. I have a few proxmox hosts running a variety of VMs and containers, and I would like to 'standardize' my deployments.
___________________________

<pre zoom labels="tunning">
Look for:
- wrong I/O scheduler
- wrong filesystem
- wrong journaling

</pre>

@[https://www.dfrws.org/sites/default/files/session-files/paper-an_analysis_of_ext4_for_digital_forensics.pdf]

<pre zoom TODO>
<span xsmall>kernel</span>
<span xsmall>crypto</span>
@[https://www.kernel.org/doc/html/v4.12/crypto/index.html]
</pre>

___________________________
KVM: {{{
- https://www.systutorials.com/136652/handling-sparse-files-on-linux/
- https://www.systutorials.com/245839/how-to-enlarge-root-partition-and-filesystem-size-of-cloud-linux-vm-at-runtime-without-rebooting-linux/
- https://www.systutorials.com/241831/how-to-resize-a-virtual-disk-of-kvm/
}}}

_________________________
Cobbler (short of "Advanced PXE" network installs)
The most common way to do network installations is network booting via PXE, which requires setup of a TFTP server and DHCP configuration.
However, PXE is not viable in some situations due to external constraints–for instance, what if your department does not have control of your DHCP server?
What if you are at home and don’t have a server of your own? Solutions for installing machines without PXE are useful in those cases.
 For virtualization technology like Xen and KVM, other fully automatic installation solutions are required.

If you’re a systems administrator, gluing all of this (PXE, reinstalls, and virtualization) together manually is something you might prefer not to do.
You’d really like a tool to do this setup and configuration for you.

Cobbler is a universal boot server that sets up everything you need for software installation–PXE, reinstalls, and virtualization. You can set up a Cobbler boot
server for your favorite distros in just a few minutes. And as your provisioning needs grow, you can take advantage of more advanced features to
further automate and simplify your systems administration requirements.
_______________________________
Windows running on KVM (Linked-in comments)
KVM vs. VirtualBox as a desktop virtualizer
Tilman Schmidt IT Generalist Top Contributor
I've been using VirtualBox for years to run a Windows VM on my OpenSuse Linux desktop. On my new notebook, which runs CentOS 6, I decided for various reasons (not the least of them the strong disapproval of the kernel development community) to give KVM a try. Two gripes I currently have:
a) I can't seem to get my existing VirtualBox VM to run with KVM. I can convert the virtual disk image just fine, but when I start it in KVM I invariably get a bluescreen with the famous message that Windows has stopped the machine in order to protect my data.
b) The Virtual Machine Manager insists that I provide the root password in order to start a VM. With VirtualBox I just had to add my user to the vboxusers group.
Comments
Sam Varshavchik
IT Consultant
Top Contributor
Well, trying to run a hypervisor with a VM image created on another hypervisor is always a hit-and-miss proposition.


I had no issues creating a new KVM, then booting and installing both Windows XP and 7.


Keep in mind that this is Windows we're talking about. If you migrate to a different VM, the guest OS is now going to see completely different virtual hardware, when it boots. Trying taking an ordinary, physical server with MS Windows installed on its hard drive, yank out its motherboard, put in a completely different motherboard, with a different class of CPU, plug in the hard drives, and try to boot. I don't think that the chances of being able to boot to the desktop, without a bluescreen, would be very good, in this situation; yet, what you have would be the exact analogue of this scenario.
Eric Ross
Network Administrator
A few years ago, I moved from VirtualBox to KVM. I had similar issues.


These may work:
- Disable any optimizations in VirtualBox for the VM, set the devices as generic as possible, and convert again.
- In KVM when the VM starts booting, press F8 to boot into Safe Mode. If it comes up, uninstall any video and chipset drivers. You'll want to install virtio drivers afterwards.


I found it easier to install from scratch.


You can start VM's at boot or from the commandline without a password. On my work server, my Virtual Machine Manager prompts me for a password to get in (I believe it has to do with XFCE starting at bootup). I manually start XFCE on my home server so I don't get prompted for a password in VMM.
Angel Docampo
Implementador soluciones Open Source en Datalab Tecnología
I can convert windows virtual machines from vmware to kvm with those steps, I'm pretty sure it will work as well from virtualbox to kvm.


As said before, windows hates to change hardware. The workaround is to tell windows is using the simplest hardware before converting, on the source virtual environment.
So, uninstall any virtualbox guest tools/additions, reboot, tell to virtualbox the hard disk is an IDE, the network adapter is an realtek 8139too or Intel E1000, and make sure video is a VGA. Boot again and download this file https://www.virtualbox.org/raw-attachment/wiki/Migrate_Windows/MergeIDE.zip , unzip it, and double click on the .reg file.
Make sure Atapi.sys, Intelide.sys, Pciide.sys, and Pciidex.sys are in the %SystemRoot%System32Drivers folder. If any are missing they can be extracted from %SystemRoot%Driver CacheI386Driver.cab which can be opened in Windows file Exlorer like a directory and then the missing files can be copied out.
Then convert the image to qcow2, set it as virtual hard disk as you did, and it should work
Then, install spice guest tools from fedora (ISO), http://alt.fedoraproject.org/pub/alt/virtio-win/latest/images/ or from spice-space.org (EXE) http://www.spice-space.org/download/windows/spice-guest-tools/


With the boot IDE disk, add a second disc, type VirtIO, and boot windows guest again. It will detect the new disk, and will install the drivers.
Halt the machine, remove second disk, change type from IDE to VirtIO of the primary disk, and boot the guest again.


It should boot without problem.


Furthermore, you can add a VirtIO network adapter as well. And video driver will be QXL, the fastest out there (It can play videos pretty well).


Hope it helps.
Alejandro G. likes this
Gustin Johnson
Sr. Linux and Windows System Administrator seeking a new opportunity, with a focus on DevOps
Don't forget to add your user to libvirtd and kvm groups. This will allow you to start/stop and otherwise manage VMs as your regular user.


You may want to track down the RedHat virtio driver disk for windows. This makes a huge difference particularly on IO.


For additional performance you will also want to specify the CPU architecture in the VM properties. I usually just click the button that clones the host OS CPU info.


Converting a VM is still kind of a pain. I usually find it less effort and headache in the long run to just rebuild the Windows VMs. I have not had any problems with Linux VMs. I have both hypervisors installed on my laptop, so I can access old VMs when I need to. You just have to remove the kvm module before loading the vbox ones.


I am also not a fan of the ancient kernels in RHEL/Cent, so I do most of my work on more recent Ubuntu installs. I have a couple of KVM hosts at home, so I prefer Ubuntu server there. I am beginning to be a huge fan of btrfs on VM hosts. There are some nice features there that are useful when working with VMs.
Muhammad Yousuf Khan
Asst: Manager IT infrastructure
i do migrate OS from Hardware, and i did migrate several VMs from VMware server x.x to KVM with the utility called Clonezilla. with 100% success result (so far).
i didnt install anything from scratch as reinstalling domain controller or installing an additional domain controller can be a problem and also cost a lot.


after migration when you boot at first your windows may not work for some time like 15 to 30 minutes. actually this will be the time when windows detecting and installing new hardware. and then it will give you a prompt to restart and thats all.


in vmware i was using vmware tool which i had uninstall before using Clonezilla. if there is anything like vmware tool and Virt tools in virtual boxl you must uninstall it before initiating the process otherwise it will give you blue screen.
Tilman Schmidt
IT Generalist
Top Contributor
Thanks for all the comments.


Regarding portability of VMs from VirtualBox to KVM: I guess I've been a bit naive there, thinking virtual machine settings could be made sufficiently similar that the Windows guest wouldn't notice the difference. Good point about uninstalling the VirtualBox specific drivers first @Eric @Angel @Muhammad, should have thought of that. But I'll probably end up ditching the old VirtualBox VM and create a new one for KVM, which (@Sam) does indeed work perfectly fine.


Regarding starting VMs without root privilege, @Alejandro @Eric it was indeed virt-manager asking for the root password on startup. But the shell commands "virsh list --all", "virsh start myvm", and "virt-viewer myvm" also work only if run as root. If run as a regular user, "virsh list --all" comes up empty, "virsh start myvm" complains "Domain not found: no domain with matching name 'myvm'", and "virt-viewer myvm" (after starting myvm with "sudo virsh start myvm") just does nothing. All of these work fine when run as root via sudo. @Gustin Adding the user to the kvm group did not change anything. There is no group libvirtd on my system.


Another (small) inconvenience when starting the VM from the command line is that it requires two commands, one (virsh start myvm) to start the VM and one (virt-viewer myvm) to get a window showing its screen. VirtualBox and virt-manager are both able display the VM console screen automatically when I start a VM. I guess I'll end up creating a shell alias to something like 'sudo "virt-viewer $1 & virsh start $1"'. (Quoting might get interesting on that one.)
Gustin Johnson
Sr. Linux and Windows System Administrator seeking a new opportunity, with a focus on DevOps
Regarding portability:
I have moved a couple of VMs from VirtualBox to kvm. The one big problem is that disk IO sucks since the kvm instance is using IDE emulation. The Windows VM refuses to let me switch to virtio while the Linux instances were no problem at all even after installing the relevant drivers.


In contrast the Windows VMs that I built on KVM have much better IO with the virtio drivers. You do have to attach the Red Hat driver ISO during the install to install the drivers so that Windows will actually install to a virtio block device. It is kind of clunky (don't forget to re-mount the Windows ISO and click the refresh button in the Windows installer) but if you snapshot a base install (trivial and fast with btrfs or cloning with virt-manager) you only need to do this once per Windows version. You could also build a custom Windows install to roll the drivers in. Microsoft has a lot of documentation and tools to help with this, though they never mention this in relation to kvm.


I have had about the same success rate moving to KVM as I have between the other hypervisors, and I have used all of the hypervisors in the x86/x86_64 world.


Regarding the root requirement:
What distribution do you have? I do not need root or sudo to run virsh on my 3 personally owned kvm hosts. All three are running various flavours of Ubuntu where I have the libvirt-bin package installed on my systems. The /etc/libvirt/libvirtd.conf file specifies the group(s) with read and write permissions (by default the libvirtd group on Ubuntu). This works locally and remotely with both virsh and virt-manager.


Regarding displays:
They suck on kvm IMHO. I usually just rdp with remmina to my Windows VMs to get copy and paste working. For Linux VMs, well I almost never need a GUI on a VM. I do have one Linux VM at home with a GUI and I use xrdp to proxy a vncserver session. There are probably better ways to do this.


There is nothing that I have found that behaves the same as VirtualBox (or VMWare workstation/player). If you do find something do let me know.


Hth,
_______________________
https://www.redhat.com/sysadmin/virtual-machine-recovery
_______________________________
GlusterFS altering a file's hash?
@[https://www.reddit.com/r/linuxadmin/comments/cht9fg/glusterfs_altering_a_files_hash_wha/

__________________
https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/windows_integration_guide/ch-configuring_authentication

Chapter 3. Using realmd to Connect to an Active Directory Domain
https://outsideit.net/realmd-sssd-ad-authentication/
_______________________
https://www.enterprisestorageforum.com/storage-hardware/memory-ballooning.html
_____________________
https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/vdo-integration
Virtual Data Optimizer (VDO) is a block virtualization technology that allows you to easily create compressed and deduplicated pools of block storage.

- Deduplication is a technique for reducing the consumption of storage resources by eliminating multiple copies of duplicate blocks.
- Compression is a data-reduction technique that works well with file formats that do not necessarily exhibit block-level redundancy, such as log files and databases. See Section 29.4.8, “Using Compression” for more detail.
___________________________
https://www.apriorit.com/dev-blog/634-qa-how-to-perform-comprehensive-linux-kernel-module-security-testing
 How to Perform Comprehensive Linux Kernel Module Security Testing

 Security testing is becoming essential for every business. Undetected bugs and security vulnerabilities can lead to expensive consequences or even losses that businesses can’t recover from.
__________________________
