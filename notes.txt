## Apropos:
  Content is versioned in git.  commits, issues and pull-requests welcome!
@[https://www.github.com/earizon/DevOps]

# Shell Scripting [[{dev_stack.shell_script]]

  #[bash_summary]
## REFERENCE SCRIPT:  [[{dev_stack.shell_script.101]]

  #!/bin/bash
  # NOTE: The Bash "syntax sugar" VAR1=$("some command") executes "some command"
  #  and assigns execution (STDOUT) output as effective value to VAR1

  # SETUP STDERR/STDOUT logging to file and console {{{
  readonly LOG_DIR="LOGS.gitignore"
  if [ ! -d ${LOG_DIR} ] ; then
     mkdir ${LOG_DIR}
  fi
  # $(whoami) will avoid collisions  among different users even if writing to the
  # same directory and serves as audit trail. # This happens frequently in DevOps when
  # executing in sudo/non-sudo contexts.
  readonly OUTPUT="${LOG_DIR}/$(basename $0).$(whoami).$(date +%Y%m%d_%Hh%Mm%Ss).log"
  ln -sf ${OUTPUT} link_last_log.$(basename $0).gitignore  # (opinionated) Improve UX, create link to latest log
  exec 3>&1
  exec 4>&2
  echo "Cloning STDOUT/STDERR to ${PWD}/${OUTPUT}"
                                           # (Opnionated) Redirect to STDOUT and file REF:
  exec &> >(tee -a "$OUTPUT")              # Comment to disable (Ussually not needed in Kubernetes/AWS-EC2/...
                                           # since console output is direcly saved to files/S3 by some external mechanism.
                                           # https://unix.stackexchange.com/questions/145651↩
                                           #   /using-exec-and-tee-to-redirect-logs-to-stdout-and-a-log-file-in-the-same-time

  exec 2>&1                                # (Opinionated). Mix errors (STDERR) with STDOUT.
                                           # Recommended to see errors in the context of normal execution.
  echo "message logged to file & console"
  # }}}

                                           # Bash syntax sugar.
  [[ `hostname` =~ -([0-9]+)$ ]] || exit 1 # <·· Check hostname match -[0-9] or exit.
  SERVER_NUMBER=${BASH_REMATCH[1]}         # <·· Otherwise asing match to var.

  global_exit_status=0
  readonly WD=$(pwd)    # Best Practice: write down current work dir are use it
                        # to avoid problems when changing dir ("cd")
                        # randomnly throughout the script execution

  readonly FILE_RESOURCE_01="${WD}/temp_data.csv"    # <- readonly: inmutable value      [[qa]]


  readonly LOCK=$(mktemp)                 # <- Make temporal file. Assign ro constant LOCK.
                                          #    Use TMP_DIR=$(mktemp --directory) to create temporal dir.

  function funCleanUpOnExit() {
    rm ${LOCK}
  }
  trap funCleanUpOnExit EXIT              # ← Clean any temporal resource (socket, file, ...) on exit

  function XXX(){
    set +e                                # <- Disable "exit on any error" for the body of function.
                                          #  REF: @[https://en.wikipedia.org/wiki/Fail-fast]
    local -r name = ${HOME}               # local: scoped to function!!!                      [[qa]]
    echo "Cleaning resource and exiting"
    rm -fO ${FILE_RESOURCE_01}
    set -e                                # <- Re-enable fail-fast.
  }

  ERR_MSG=""
  function funThrow {
      if [[ $STOP_ON_ERR_MSG != false ]] ; then
        echo "ERR_MSG DETECTED: Aborting now due to "
        echo -e ${ERR_MSG}
        if [[ $1 != "" ]]; then
            global_exit_status=$1 ;
        elif [[ $global_exit_status == 0 ]]; then
            global_exit_status=1 ;
        fi
        exit $global_exit_status
      else
        echo "ERR_MSG DETECTED: "
        echo -e ${ERR_MSG}
        echo "WARN: CONTINUING WITH ERR_MSGS "

        global_exit_status=1 ;
      fi
      ERR_MSG=""
  }

  exec 100>${LOCK}                        # Simple linux-way to use locks.
  flock 100                               # First script execution will hold the lock
  if [[ $? != 0 ]] ; then                 # Next ones will have to wait. Use -w nSecs
      ERR_MSG="HOME ENV.VAR NOT DEFINED"  # to fail after timeout or -n to fail-fast
      funThrow 10 ;                       # lock will automatically be liberated on
  fi                                      # exit. (no need to unlock manually)
                                          # <a href="https://www.putorius.net/lock-files-bash-scripts.html">REF</a>

  # SIMPLE WAY TO PARSE/CONSUME ARGUMENTS WITH while-loop.
  while [  $#  -gt 0 ]; do  # $#  number of arguments
    case "$1" in
      -l|--list)
        echo "list arg"
        shift 1                       # <- consume arg      ,  $# = $#-1
        ;;
      -p|--port)
        export PORT="${2}"
        shift 2                       # <- consume arg+value,  $# = $#-2
        ;;
      -h|--host)
        export HOST="${2^^}"         # <-  ^^ suffix: Convert ${2} to upper case
        shift 2                       # <-  consume arg+value, $# = $#-2
        ;;
      *)
        echo "non-recognised option '$1'"
        shift 1                       # <- consume arg       , $# = $#-1
    esac
  done

  set -e                                   # At this point all variable must be defined. Exit on any error.

  function preChecks() {
    # Check that ENV.VARs and parsed arguments are in place
    if [[ ! ${HOME} ]] ; then ERR_MSG="HOME ENV.VAR NOT DEFINED" ; funThrow 41 ; fi
    if [[ ! ${PORT} ]] ; then ERR_MSG="PORT ENV.VAR NOT DEFINED" ; funThrow 42 ; fi
    if [[ ! ${HOST} ]] ; then ERR_MSG="HOST ENV.VAR NOT DEFINED" ; funThrow 43 ; fi
    set -u # From here on, ANY UNDEFINED VARIABLE IS CONSIDERED AN ERROR.
  }

  function funSTEP1 {
    echo "STEP 1: $HOME, PORT:$PORT, HOST: $HOST"
  }
  function funSTEP2 { # throw ERR_MSG
    ERR_MSG="My favourite ERROR@funSTEP2"
    funThrow 2
  }

  cd $WD ; preChecks
  cd $WD ; funSTEP1
  cd $WD ; funSTEP2

  echo "Exiting with status:$global_exit_status"
  exit $global_exit_status

## INIT VARS AND CONSTANTS:
  # complete Shell parameter expansion list available at:
  # - @[http://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html]
  var1=$1 # init var $1 with first param
  var2=$# # init var $1 with number of params
  var3=$! # init var with PID of last executed command.
  var4=${parameter:-word} # == $parameter if parameter set or 'word' (expansion)
  var5=${parameter:=word} # == $parameter if parameter set or 'word' (expansion), then parameter=word
  var6=${parameter:?word} # == $parameter if parameter set or 'word' (expansion) written to STDERR, then exit.
  var7=${parameter:+word} # == var1       if parameter set or 'word' (expansion).
  var8=${var1^^}          # init var2 as var1 UPPERCASE.
  var9=${parameter:offset}         #  <- Substring Expansion. It expands to up to length characters of the value
  varA=${parameter:offset:length}  |     of parameter starting at the character specified by offset.
                                   |     If parameter is '@', an indexed array subscripted by '@' or '*', or an
                                   |     associative array name, the results differ.
  readonly const1=${varA}

## CONCURRENT PROCESS BARRIER SYNCHRONIZATION
  Wait for background jobs to complete example:
  (
    ( sleep 3 ; echo "job 1 ended" ) &
    ( sleep 1 ; echo "job 2 ended" ) &
    ( sleep 1 ; echo "job 3 ended" ) &
    ( sleep 9 ; echo "job 4 ended" ) &
    wait ${!}       # alt.1: Wait for all background jobs to complete
  # wait %1 %2 %3   # alt.2: Wait for jobs 1,2,3. Do not wait for job 4
    echo "All subjobs ended"
  ) &

## SIMPLIFIED READ-EVALUATE-PARSE-LOOP (REPL) IN BASH
  REPL stands for Read-eval-print loop: More info at:
  @[https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop]

  while  [[ ${LANGUAGE} != "EXIT" ]] ; do # {
    select LANGUAGE in BASH CSHARP JAVA PHP PYTHON EXIT
    do # {
      echo "Selected language is $language"
    done #
  done # }

  NOTE: More complex input can be done replacing the line:
          select INPUT in OPT1 OPT2 ...
          do
           ...
          done
        by
          read -p "PROMPT" INPUT
          funComplexParsingAndEvaluationOver $INPUT

## 'test' CONDITIONAL BRANCHING [[{]]
  (man test summary from GNU coreutils for more info)

  test   EXPRESSION  # ← EXPRESSION true/false sets the exit status.
  test [ EXPRESSION ]

  -n STRING                  # STRING length >0
                             # (or just STRING)
  -z STRING                  #  STRING length == 0
  STRING1 = STRING2          # String equality
  STRING1 != STRING2         # String in-equality


  INTEGER1 -eq INTEGER2      # ==
  INTEGER1 -ge INTEGER2      # <=
  INTEGER1 -gt INTEGER2
  INTEGER1 -le INTEGER2
  INTEGER1 -lt INTEGER2
  INTEGER1 -ne INTEGER2
  ^^^^^^^^
    NOTE:  INTEGER can be -l STRING (length of STRING)

   FILE TEST/COMPARISION
    WARN:  Except -h/-L, all FILE-related tests dereference symbolic links.
  -e FILE                    # FILE exists
  -f FILE                    # FILE exists and is a1regular file
  -h FILE                    # FILE exists and is   symbolic link  (same as -L)
  -L FILE                    #                                     (same as -h)
  -S FILE                    # FILE exists and is   socket
  -p FILE                    # FILE exists and is a named pipe
  -s FILE                    # FILE exists and has   size greater than zero


  -r FILE                    # FILE exists and read  permission is granted
  -w FILE                    # FILE exists and write permission is granted
  -x FILE                    # FILE exists and exec  permission is granted

  FILE1  -ef FILE2           # ← same device and inode numbers
  FILE1 -nt FILE2            # FILE1 is newer (modification date) than FILE2
  FILE1 -ot FILE2            # FILE1 is older (modification date) than FILE2
  -b FILE                    # FILE exists and is block special
  -c FILE                    # FILE exists and is character special
  -d FILE                    # FILE exists and is a directory
  -k FILE                    # FILE exists and has its sticky bit set


  -g FILE                    # FILE exists and is set-group-ID
  -G FILE                    # FILE exists and is owned by the effective group ID
  -O FILE                    # FILE exists and is owned by the effective user ID
  -t FD   file descriptor FD is opened on a terminal
  -u FILE FILE exists and its set-user-ID bit is set
  • BOOLEAN ADITION:
    WARN : inherently ambiguous.  Use
    EXPRESSION1 -a EXPRESSION2 # AND # 'test EXPR1 && test EXPR2' is prefered
    EXPRESSION1 -o EXPRESSION2 # OR  # 'test EXPR1 || test EXPR2' is prefered
  [[}]]

    WARN,WARN,WARN : your shell may have its own version of test and/or '[',
                     which usually supersedes the version described here.
                     Use /usr/bin/test to force non-shell ussage.

  Full documentation at: @[https://www.gnu.org/software/coreutils/]
[[}]]

## (KEY/VALUE) MAPS (Bash 4+)
  (also known as associative array or hashtable)

  Bash Maps can be used as "low code" key-value databases.
  Very useful for daily config/devops/testing task.
  Ex:
  #!/bin/bash            # ← /bin/sh will fail. Bash 4+ specific

  declare -A map01       # ← STEP 1) declare Map

  map01["key1"]="value1" # ← STEP 2) Init with some elements.
  map01["key2"]="value2" #   Visually map01 will be a table similar to:
  map01["key3"]="value3" #   key  │ value
                         #   ─────┼───────
                         #   key1 │ value1  ← key?, value? can be any string
                         #   key2 │ value2
                         #   key3 │ value3

    keyN="key2"          # ← STEP 3) Example Ussage
    ${map01[${key_var}]} #   ← fetch value for key "key2"
    ${!map01[@]}         #   ← fetch keys  . key2 key3 key1
    ${map01[@]}          #   ← fetch values. (value2 value3 value1)

    for keyN in "${!map01[@]}";      # ← walk over keys:
    do                               # (output)
      echo "$keyN : ${map01[$keyN]}" # key1 : value1
    done                             # key2 : value2
                                     # key3 : value3

  #[curl_summary]
## Curl (network client swiss Army nkife) [[{networking.curl,troubleshooting,qa.testing]]
- Suport for DICT, FILE, FTP, FTPS, GOPHER, HTTP GET/POST, HTTPS, HTTP2, IMAP,
             IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS,
             SMTP, SMTPS, TELNET,  TFTP, unix socket protocols.
- Proxy support.
- kerberos support.
- HTTP  cookies, etags
- file transfer resume.
- Metalink
- SMTP / IMAP Multi-part
- HAProxy PROXY protocol
- ...

### Ussage Summary:
  $ curl http://site.{a,b}.com
   --silent                 <·· Disable progress meter
   --verbose                <·· Debug
   --anyauth                <·· make curl figure out auth. method
                               (--basic, --digest, --ntlm, and --negotiate)
                               not recommended if uploading from STDIN since
                               data can be sent 2+ times
                               - Used together with -u, --user.
   --cacert cert_file_path  <·· Alt: Use CURL_CA_BUNDLE
                                   - See also --capath dir, --cert-status,  --cert-type PEM|DER|...
   --cert certificate[:pass]<·· Use cert to indentify curl client
   --ciphers TLS_ciphers_list
   --compressed             <·· Request compressed response. Save uncompressed
   --config curl_args_list
   --connect-timeout secs
                                HTTP Post Data:
   --data-binary    data        <·· alt 1: posts data with no extra processing whatsoever.
   --data-urlencode data        <·· alt 2: URLencoded
   --data           data        <·· alt 3: application/x-www-form-urlencoded (browser like forms)
                    └──┴─·········· Or @path_to_file_with_data
                                    Or @- to use STDIN
   --header ...
   --limit-rate speed
   --location                   <·· follow redirects
   --include                    <·· Include HTTP response headers in output
   --oauth2-bearer ...          <·· (IMAP POP3 SMTP)
   --fail-early                 <·· Fail as soon as possible
   --continue-at -              <·· Continue a partial download
   --output out_file            <·· Write output to file (Defaults to stdout)
                                    Use also --create-dirs to create unexisting dirs.

### Curl: List remote contents
  $ curl --list-only https://..../dir1/ ← List contents of remote dir
[[}]]

## Kapow! Shell Script to HTTP API [[{web_hook,01_PM.low_code,git,monitoring.prometheus,dev_stack.shell_script,dev_stack.kubernetes,]]
@[https://github.com/BBVA/kapow]    [[notifications.jira,InfraAsCode.ansible,git,git.github,notifications.slack]]
  (by BBVA-Labs Security team members)
  " If you can script it, you can HTTP it !!!!"

 Ex:
 Initial Script:
   $ cat /var/log/apache2/access.log | grep 'File does not exist'

 To expose it as HTTP:

   $ cat search-apache-errors
   #!/usr/bin/env sh
   kapow route add /apache-errors - <-'EOF'
       cat /var/log/apache2/access.log | grep 'File does not exist' | kapow set /response/body
   EOF

 Run HTTP Service like:

 $ kapow server search-apache-errors  ← Client can access it like
                                        curl http://apache-host:8080/apache-errors
                                        [Fri Feb 01 ...] [core:info] File does not exist: ../favicon.ico
                                        ...

    We can share information without having to grant SSH access to anybody.


  Recipe: Run script as a given user:
  # Note that `kapow` must be available under $PATH relative to /some/path
  kapow route add /chrooted\
      -e 'sudo --preserve-env=KAPOW_HANDLER_ID,KAPOW_DATA_URL \
          chroot --userspec=sandbox /some/path /bin/sh -c' \
          -c 'ls / | kapow set /response/body'
[[}]]

## WebHook  [[{dev_stack.shell_script,01_PM.TODO]]
@[https://github.com/adnanh/webhook]
  - lightweight incoming webhook server to run shell commands
    You can also pass data from the HTTP request (such as headers,
    payload or query variables) to your commands. webhook also allows you
    to specify rules which have to be satisfied in order for the hook to
    be triggered.

  - For example, if you're using Github or Bitbucket, you can use webhook
    to set up a hook that runs a redeploy script for your project on your
    staging server, whenever you push changes to the master branch of
    your project.

  - Guides featuring webhook:
    - Webhook and JIRA by @perfecto25                                      [[jira]]
    - Trigger Ansible AWX job runs on SCM (e.g. git) commit by @jpmens     [[ansible]]
    - Deploy using GitHub webhooks by @awea [git][github]
    - Setting up Automatic Deployment and Builds Using Webhooks by Will
      Browning
    - Auto deploy your Node.js app on push to GitHub in 3 simple steps by  [[git.github]]
      Karolis Rusenas
    - Automate Static Site Deployments with Salt, Git, and Webhooks by     [[git]]
      Linode
    - Using Prometheus to Automatically Scale WebLogic Clusters on         [[prometheus,k8s,weblogic]]
      Kubernetes by Marina Kogan
    - Github Pages and Jekyll - A New Platform for LACNIC Labs by Carlos
      Martínez Cagnazzo
    - How to Deploy React Apps Using Webhooks and Integrating Slack on     [[{notifications.slack}]]
      Ubuntu by Arslan Ud Din Shafiq
    - Private webhooks by Thomas
    - Adventures in webhooks by Drake
    - GitHub pro tips by Spencer Lyon [github]
    - XiaoMi Vacuum + Amazon Button = Dash Cleaning by c0mmensal
    - Set up Automated Deployments From Github With Webhook by Maxim Orlov
      VIDEO: Gitlab CI/CD configuration using Docker and adnanh/webhook
      to deploy on VPS - Tutorial #1 by Yes! Let's Learn Software
[[}]]

## Bash-it: community bash commands [[{]]
 https://www.tecmint.com/bash-it-control-shell-scripts-aliases-in-linux/
- bundle of community bash commands and scripts for Bash 3.2+,
  which comes with autocompletion, aliases, custom functions, ....
- It offers a useful framework for developing, maintaining and
  using shell scripts and custom commands for your daily work.
[[}]]

## Best Practices [[{01_PM.TODO]]
@[https://sharats.me/posts/shell-script-best-practices/]
[[}]]
[[dev_stack.shell_script}]]

# GIT [[{git]]
### External Links:
* @[https://git-scm.com/book/en/v2]
* @[https://learnxinyminutes.com/docs/git/]
* @[https://learngitbranching.js.org/?demo]
* Related:
  See UStore: Distributed Storage with rich semantics!!!
  @[https://arxiv.org/pdf/1702.02799.pdf]
### Who-is-who:
  (Forcibly incomplete but still quite pertinent list of core people and companies)
* Linus Torvald: He initiated the project to fix problems
  with distributed development of the Linux Kernel
* Junio C. Hamano:  lead git maintainer (+8700 commits)
  @[https://git-blame.blogspot.com/]

### What's new: [[{]]
- 2.28:
@[https://github.blog/2020-07-27-highlights-from-git-2-28/]

 - Git 2.28 takes advantage of 2.27 commit-graph optimizations to  [[performance]]
   deliver a handful of sizeable performance improvements.

- 2.27:
 - commit-graph file format was extended to store changed-path Bloom
   filters. What does all of that mean? In a sense,
   this new information helps Git find points in history that touched a
   given path much more quickly (for example, git log -- <path>, or git [[performance]]
   blame).

- 2.25:
@[https://www.infoq.com/news/2020/01/git-2-25-sparse-checkout/]
  500+ changes since 2.24.

  Sparse checkouts are one of several approaches Git supports to improve   [scalability]
  performance when working with big(huge or monolithic) repositories.      [monolitic]
   They are useful to keep working directory clean by specifying which     [performance]
  directories to keep. This is useful, for example, with repositories
  containing thousands of directories.

  See also: http://schacon.github.io/git/git-read-tree.html#_sparse_checkout

- 2.23:
  https://github.blog/2019-08-16-highlights-from-git-2-23
[[}]]

  #[git_summary]
## GIT "Full Journey" [[{git.101,02_DOC_HAS.diagram,01_PM.WiP]]

  Non-normative Git server setup for N projects with M teams of L users
  ─────────────────────────────────────────────────────────────────────

### CONTEXT:
- ssh access has been enabled to server (e.g: $ $ sudo apt install openssh-server   )
- Ideally ssh is protected. See for example:
   @[../DevOps/linux_administration_summary.html#knockd_summary]
   (Alternatives include using GitHub,GitLab,BitBucket, AWS/Scaleway/Azure/... )

-  We want to configure linux users and groups to match a "permissions layout" similar to:
    GIT_PROJECT1 ···→ Linux Group teamA ····→ R/W permssions to /var/lib/teamA/project01 *1
    GIT_PROJECT2 ···→ Linux Group teamA ····→ R/W permssions to /var/lib/teamA/project02
                      └───────┬────────┘
                       alice, bob,...
    GIT_PROJECT3 ···→ Linux Group teamB ····→ R/W permssions to /var/lib/teamB/project03
    GIT_PROJECT4 ···→ Linux Group teamB ····→ R/W permssions to /var/lib/teamB/project04
                      └───────┬────────┘
                       franc, carl, ...
    GIT_PROJECT5 ···→ ...
  *1: setup /var/lib/teamA/project01 like:
  $ $ sudo mkdir -p /var/lib/teamA/project01                 ← create directory
  $ $ cd /var/lib/teamA/project01
  $ $ sudo git init --bare                                   ← INIT NEW GIT BARE DIRECTORY !!!!
                                                               (GIT OBJECT DATABASE for
                                                                commits/trees/blogs, ...)
  $ $ DIR01=/var/lib/teamA/project01
  $ $ sudo find ${DIR01} -exec chown -R nobody:teamA {} \;   ← Fix owner:group_owner for dir. recursively
  $ $ sudo find ${DIR01} -type d -exec chmod g+rwx {} \;     ← enable read/wr./access perm. for dirs.
  $ $ sudo find ${DIR01} -type f -exec chmod g+rw  {} \;     ← enable read/write      perm. for files

    Finally add the desired linux-users to the 'teamA' linux-group at will. More info at:
    @[../DevOps/linux_administration_summary.html#linux_users_groups_summary] )


  Non-normative ssh client access to Git remote repository using ssh
  ──────────────────────────────────────────────────────────────────
### PRE-SETUP) Edit ~/.bashrc to tune the ssh options for git ading lines similar to:
  + GIT_SSH_COMMAND=""
  + GIT_SSH_COMMAND="${GIT_SSH_COMMAND} -oPort=1234 "                 ← connect to port 1234 (22 by default)
  + GIT_SSH_COMMAND="${GIT_SSH_COMMAND} -i ~/.ssh/privKeyServer.pem " ← private key to use when authenticating to server
  + GIT_SSH_COMMAND="${GIT_SSH_COMMAND} -u myUser1 "                  ← ssh user and git user are the same when using ssh.
  + GIT_SSH_COMMAND="${GIT_SSH_COMMAND} ..."                          ← any other suitable ssh options (-4, -C, ...)

    Optionally add your GIT URL like:
  $ + export GIT_URL="myRemoteSSHServer"
  $ + export GIT_URL="${GIT_URL}/var/lib/my_git_team   ← Must match path in server (BASE_GIT_DIR)
  $ + export GIT_URL="${GIT_URL}/ourFirstProject"      ← Must match name in server (PROJECT_NAME)

* PRE-SETUP) Modify PS1 prompt (Editing $HOME/.bashrc) to look like:
  PS1="\h[\$(git branch 2>/dev/null | grep ^\* | sed 's/\*/branch:/')]"               $( ... ) ==   exec. ... as script.
           └─────────────     show git branch    ───────────────────┘                            + Assign STDOUT to var.
  export PS1="${PS1}@\$(pwd |rev| awk -F / '{print \$1,\$2}' | rev | sed s_\ _/_) \$ "           (bash "syntax sugar")
               └────────────── show current and parent dir. only ────────┘

  host1 $                           ← PROMPT BEFORE
  host01[branch: master]@dir1/dir2  ← PROMPT AFTER

* Finally clone the repo like:
  $ git clone   myUser1 @${GIT_URL}   # <·· execution will warn about cloning empty directory.
  $ cd ourFirstProject                # <·· move to local clone.
  $ ...                               # <·· Continue with standards git work flows.
  $ git add ...
  $ git commit ...


## COMMON (SIMPLE) GIT FLOWS

  ┌─ FLOWS 1: (Simplest flow) no one else pushed changes before our push.────────────────────────────────────
  │           NO CONFLICTS CAN EXISTS BETWEEN LOCAL AND REMOTE WORK
  │  local ─→ git status ─→ git add . ─→ git commit ··································→ git push \
  │  edit     └───┬────┘    └───┬────┘   └───┬────┘                                     origin featureX
  │               │         add file/s       │                                         └─────┬─────────┘
  │       display changes   to next commit   │                                       push to featureX branch
  │       pending to commit              commit new file history                     at remote repository.

  ┌─ FLOWS 2: someone else pushed changes before us,  ───────────────────────────────────────────────────────
  │           BUT THERE ARE NO CONFLICTS (EACH USER EDITED DIFFERENT FILES)
  │  local → git status → git add . → git commit ─→ git pull ·························→ git push \
  │  edit                                          └───┬───┘                            origin featureX
  │               • if 'git pull' is ommitted before 'git push', git will abort warning about remote changes
  │                 conflicting with our local changes. 'git pull' will download remote history and since
  │                 different files have been edited by each user, an automatic merge is done  (local changes
  │                  + any other user's remote changes). 'git pull' let us see other's people work locally.

  ┌─ FLOW 3: someone else pushed changes before our push,  ──────────────────────────────────────────────────
  │          BUT THERE ARE  CONFLICTS (EACH USER EDITED ONE OR MORE COMMON FILES)
  │  local → git status → git add . → git commit ─→ git pull ┌→ git add  → git commit → git push \
  │  edit                                              ↓     ↑  └──┬──┘                 origin featureX
  │                                             "fix conflicts" mark conflicts as
  │                                             └─────┬──────┘  resolved
  │                                  manually edit conflicting changes (Use git status to see conflicts)

  ┌─ FLOW 4: Amend local commit ─────────────────────────────────────────────────────────────────────────────
  │  local → git status → git add . → git commit  → git commit ─amend ...→ git commit → git push \
  │  edit                                                                               origin featureX

  ┌─ GIT FLOW: Meta-flow using WIDELY ACCEPTED BRANCHES RULES  ──────────────────────────────────────────────
  │  to manage common issues when MANAGING AND VERSIONING SOFTWARE RELEASES
  │  ┌───────────────────┬──────────────────────────────────────────────────────────────────────────────────┐
  │  │ Standarized       │ INTENDED USE                                                                     │
  │  │ branch names      │                                                                                  │
  │  ├───────────────────┼──────────────────────────────────────────────────────────────────────────────────┤
  │  │ feature/...       │ Develop new features here. Once developers /QA tests are "OK" with new code      │
  │  │                   │ merge back into develop. If asked to switch to another task just commit changes  │
  │  │                   │to this branch and continue later on.                                             │
  │  ├───────────────────┼──────────────────────────────────────────────────────────────────────────────────┤
  │  │develop            │ RELEASE STAGING AREA: Merge here feature/... completed features NOT YET been     │
  │  │                   │ released in other to make them available to other dev.groups.                    │
  │  │                   │ Branch used for QA test.                                                         │
  │  ├───────────────────┼──────────────────────────────────────────────────────────────────────────────────┤
  │  │release/v"X"       │ stable (release tagged branch). X == "major version"                             │
  │  ├───────────────────┼──────────────────────────────────────────────────────────────────────────────────┤
  │  │hotfix branches    │ BRANCHES FROM A TAGGED RELEASE. Fix quickly, merge to release and tag in release │
  │  │                   │ with new minor version. (Humor) Never used, our released software has no bugs    │
  │  └───────────────────┴──────────────────────────────────────────────────────────────────────────────────┘
  │
  │  • master branch ← "Ignore".
  │  ├─ • develop (QA test branch) ·················• merge ·················· • merge ┐  ...• merge ┐
  │  │  │                                           ↑ feat.1                   ↑       ·     ↑       ·
  │  │  ├→ • feature/appFeature1 • commit • commit ─┘  ························│·······↓ ... ┘       ·
  │  │  │     (git checkout -b)                                                │       ·             ·
  │  │  │                                                                      │       ·             ·
  │  │  ├→ • feature/appFeature2 • commit • commit • commit • commit • commit ─┘       ·  ┌··········┘
  │  │                                                                                 ·  ·(QA test "OK")
  │  │                      ┌··········←·(QA Test "OK" in develop, ready for release)··┘  ·
  │  │  ...                 v                                                             v
  │  ├─ • release/v1 ·······• merge&tag ┐         • merge&tag ┐         • merge&tag ······• merge&tag
  │  │                        v1.0.0    ·         ↑ v1.0.1    ·         ↑ v1.0.2            v1.1.0
  │  │                        *1        ↓         · *1        ·         · *1                *1
  │  │                                  └ hotfix1 •           └ hotfix2 •
  │  │                                  (git checkout -b)
  │  ├─ • release/v2 ····

  *1 Each merge into release/v"N" branch can trigger deployments to acceptance and/or production enviroments
     triggering new Acceptance tests. Notice also that deployments can follow different strategies
     (canary deployments to selected users first, ...).

## Git Recipes
                                            PLAYING WITH BRANCHES
  $ git checkout    newBranch             ← swith to local branch (use -b to create if not yet created)
  $ git branch -av                        ←  List (-a)ll existing branches
  $ git branch -d branchToDelete          ← -d: Delete branch
  $ git checkout --track "remote/branch"  ← Create new tracking branch (TODO)
  $ git checkout v1.4-lw                  ← Move back to (DETACHED) commit. ('git checkout HEAD' to reattach)
 $ git remote update origin --prune       ← Update local branch to mirror remote branches in 'origin'

                                            VIEW COMMIT/CHANGES HISTORY
  $ git log -n 10                         ← -n 10. See only 10 last commits.
  $ git log -p path_to_file               ← See log for file with line change details (-p: Patch applied)
  $ git log --all --decorate \            ← PRETTY BRANCH PRINT Alt.1
    --oneline --graph                       REF @[https://stackoverflow.com/questions/1057564/pretty-git-branch-graphs]
  $ git log --graph --abbrev-commit \     ← PRETTY BRANCH PRINT  Alt.2
     --decorate --date=relative --all


                                            UPDATE ALL REMOTE BRANCHES TO LOCAL REPO
  (REF: https://stackoverflow.com/questions/10312521/how-to-fetch-all-git-branches=
  for remote in `git branch -r`;             # ← add remote branches on server NOT yet tracked locally
     do git branch \                         #   (pull only applies to already tracked branches)
        --track ${remote#origin/} $remote;
  done

  $ git fetch --all                            # ← == git remote update.
                                               #    updates local copies of remote branches
                                               #    probably unneeded?. pull already does it.
                                               #    It is always SAFE BUT ...
                                               #    - It will NOT update local branches (tracking remote branches)
                                               #    - It will NOT create local branches (tracking remote branches)
  $ git pull --all                             # ← Finally update all tracked branches.

                                            TAGS:
  $ git tag                               ← List tags
  → v2.1.0-rc.2
  → ...
  $ git tag -a v1.4 -m "..." 9fceb..      ← Create annotated tag (recomended), stored as FULL OBJECTS.
                                            It contains tag author/mail/date, tagging message (-m).
                                            can be checksummed and optionally SIGNED/VERIFIED with GPG.
                                            if commit ommited (9fceb..) HEAD is used)
  $ git tag v1.4-lw                       ← Create lightweight tag ("alias" for commit-checksum)

                                            SHARING/PUSHING TAGS
                                            WARN : 'git push' does NOT push tags automatically
  $ git push origin v1.5                  ← Share 'v1.5' tag to remote 'origin' repo
  $ git push origin --tags                ← Share all tags
  $ git tag -d v1.4-lw                    ← Delete local tag (remote tags will persist)
  $ git push origin --delete v1.4-lw      ← Delete remote tag. Alt 1
  $ git push origin :refs/tags/v1.4-lw    ← Delete remote tag. Alt 2
                    └────────────────┴─── ← null value before the colon is being pushed to the
                                             remote tag name, effectively deleting it.
  $ git show-ref --tags                   ← show mapping tag ←→ commit
  → 75509731d28d... refs/tags/v2.1.0-rc.2
  → 8fc0a3af313d... refs/tags/v2.1.1
  → ...
                                            REVERTING CHANGES
 $ git reset --hard HEAD~1                ← revert to last-but-one (~1) local commit (Not yet pushed)
                                            (effectively removing last commit from local history)
 $ git checkout path/fileN                ← revert file not yet "git-add"ed or removed from FS to last commited ver.
 $ git checkout HEAD^ -- path/...         ← revert commited file to last-but-one commit version
 $ git revert ${COMMIT_ID}                ← add new commit cancelling changes in $COMMIT_ID. Previous
                                            commit is not removed from history. Both are kept on history.
 $ git clean -n                           ← Discard new "git-added" files. -n == -dry-run, -f to force
 $ git reset path/fileA                   ← Remove from index file "git-added" by mistake (with 'git add .')
                                            (probably must be added to .gitignore)

 $ git checkout N -- path1                ← Recover file at commit N (or tag N)
 $ git checkout branch1 -- path1          ← Recover file from branch1
                                            origin/branch1 to recover from upstream -vs local- branch.


                                            CLONING REMOTES
  $ git clone --depth=1  \                ← Quick/fast-clone (--depth=1) with history truncated to last N commits.
                                            Very useful in CI/CD tasks.
        --single-branch \                 ← Clone only history leading to tip-of-branch (vs cloning all branches)
                                            (implicit by previous --depth=... option)
        --branch '1.3' \                  ← branch to clone (defaults to HEAD)
        ${GIT_URL}                        To clone submodules shallowly, use also --shallow-submodules.

## Track code changes
REF: @[https://git-scm.com/book/en/v2/Appendix-C:-Git-Commands-Debugging]

Methods to track who changed and/or when a change(bug) was introduced include:
### git bisect : find first commit introducing a change(bug, problem, ...) through automatic binary search .
@[https://git-scm.com/book/en/v2/Git-Tools-Debugging-with-Git#_binary_search]
  · git-blame helps to find recently introduced bugs.
  · git-bisect helps find bugs digged many commits down in history.
  · Ussage example:

                               MANUAL BISECT SEARCH
    $ git bisect start       ← start investigating issue.
    (run tests)
    $ git bisect bad         ← tell git that current commit is broken
    (run tests)
    $ git bisect good v1.0   ← tell git that current commit is OK
    Bisecting: 6 revisions↲  ← Git counts about 12 commits between
    left to test after this    "good" and "bad" and checks out middle one
    (run tests)
    ...
    b04... is 1st bad commit ← repeat git bisect good/bad until reaching
                               1st bad commit.
    $ git bisect reset       ← DON'T FORGET: reset after finding commit.

                               AUTOMATING BISECT SEARCH
  $ git bisect start HEAD v1.0
  $ git bisect run test.sh   ← test.sh must return 0 for "OK" results
                               non-zero otherwise.

### git blame : annotates lines-of-files with:
@[https://git-scm.com/book/en/v2/Git-Tools-Debugging-with-Git#_file_annotation]
  $ git blame -L 69,82 -C path2file  ← display last commit+committer for a given line
                                       -C: try to figure out where snippets of code
                                           came from (copied/file moved)
  b8b0618cf6fab (commit_author1 2009-05-26 ... 69) ifeq
  b8b0618cf6fab (commit_author1 2009-05-26 ... 70)
  ^1da177e4c3f4 (commit_author2 2005-04-16 ... 71) endif
  ^                                            ^^
  prefix '^' marks initial commit for line    line


### git grep : find any string/regex in any file in any commit, working directory (default) or index.
@[https://git-scm.com/book/en/v2/Git-Tools-Searching#_git_grep]
  •  Much faster than standard 'grep' UNIX command!!!
  $ git grep -n      regex01  ← display file:line   matching regex01 in working dir.
                                -n/--line-number: display line number
                                Use -p / --show-functions to display enclosing function
                                (Quick way to check where something is being called from)
  $ git grep --count regex01  ← Summarize file:match_count matching regex01 in working dir.

  $ git grep                  ← display file:line matching
      -n -e '#define' --and \ ← '#define' and
       \( -e ABC -e DEF \)      ( ABC or DEF )
      --break --heading \     ← split up output into more readable format
      "v1.8.0"                      ← search only in commit with tag "v1.8.0"

  See also ripgrep, claiming to be faster than `git grep`

  https://github.com/BurntSushi/ripgrep

### Git Log Searching:
  $ git log -S ABC --oneline ← log only commits changing the number-of-occurrences of "ABC"
  e01503b commit msg ...       Replace -S by -G for REGEX (vs string).
  ef49a7a commit msg ...

### Line history Search:
  $ git log -L :funABC:file.c ← git will try to figure out what the bounds of
                                function funABC are, then look through history and
                                display every change made.
                                If programming lang. is not supported, regex can be
                                used like {: -L '/int funABC/',/^[}]/:file.c
                                range-of-lines or single-line-number can be used to
                                filter out non interesting results.

## Git Plumbings
* Summary extracted from:
  @[https://alexwlchan.net/a-plumbers-guide-to-git/1-the-git-object-store/]
  @[https://alexwlchan.net/a-plumbers-guide-to-git/2-blobs-and-trees/]
  @[https://alexwlchan.net/a-plumbers-guide-to-git/3-context-from-commits/]
  @[https://alexwlchan.net/a-plumbers-guide-to-git/4-refs-and-branches/]

$ git init   ← creates an initial layout containing (Alternatively $ $git clone ... ª from existing remote repo )
  ✓.git/objects/, ✓ .git/refs/heads/master, ✓ .git/HEAD (pointing to heads/master initially)
  ✓.git/description (used by UIs), ✓.git/info/exclude (local/non-commited .gitignore),
  ✓.git/config, ✓.git/hooks/

   ~/.git/index  ←············  binary file with staging area data (files 'git-added' but not yet commited)
                                Use (porcelain) $ $ git ls-files   to see indexes files (git blobs)
        ┌─.git/objects/  (  GIT OBJECT STORE  ) ─────────┐      $ $ echo "..." > file1.txt
        │                                                │      $ $ git hash─object ─w file1.txt
┌········→ • /af/3??? •···→ •/a1/12???                   │          └───────────┬────────────────┘
·       │  │(2nd commit)                      ┌············ save to Object Store┘content─addressable File System.
·       │  v                                  v          │  WARN : Original file name lost. We need to add a mapping
· ┌··┬···→ • /5g/8... •···→ • /32/1... •┬··→• /a3/7... • │   (file_name,file_attr) ←→ hash to index like:
· ·  ·  │   (1st commit)    ┌··········┘├··→• /23/4... • │   $ $ git update-index --add file1.txt (git Plumbing)
· ·  ·  │                   ·           └···┐            │┌· Finally an snapshot of the index is created like a tree:
· ·  ·  │                   ·               ·            │·$ $ git write-tree                 .git/index snapshot to tree
· ·  ·  │                   ├─····························┘  ( /af/9???... tree object will be added to Obj.Store)
· ·  ·  │                   ·               ·            │ $ $ git cat-file -p ${tree_hash}
· ·  ·  │                   ·               ·            │     100644 blob b133......  file1.txt  ← Pointer+file_name to blob
· ·  ·  │                   ·               ·            │     040000 tree 8972......  subdir...  ← Pointer+"dirname" to (sub)tree
· ·  ·  │                   ·               ·            │     ...
· ·  ·  │                   ·               ·            │     ^^^^^^ ^^^^ ^^^^^^^^^^  ^^^^^^^^^^^^
· ·  ·  │                   ·               ·            │     file   type content     Name of file
· ·  ·  │                   ·               ·            │     permis.     address.ID
· ·  ·  │                   ·               ·            │ ☞KEY-POINT:☜
· ·  ·  │                   v               v            │  Starting at a tree, we can rebuild everything it points to
· ·  ·  │                   • /af/9... •┬··→• /12/d... • │  All that rest is mapping trees to some "context" in history.
· ·  ·  │                               └··→• /34/2... • │
· ·  ·  │  ^^^^^^^^^^^^     ^^^^^^^^^^^^    ^^^^^^^^^^^^ │  Plumbing "workflow" summary:
· ·  ·  │    commits          Trees           Blobs      │← Add 1+ Blobs → Update Index → Snapshot to Tree
· ·  ·  └────────────────────────────────────────────────┘  → create commit pointing to tree of "historical importance"
· ·  └·······················─┬──────────────────────┐        → create friendly refs to commits
· · $ $ echo "initial commit" | git commit-tree 321.....   ← create commit pointing to tree of "historical importance"
· ·     af3...                                               Use also flag '-p $previous_commit' to BUILD A LINEAR ORDERED
· ·                                                          HISTORY OF COMMITS !!!
· ·
· · $ $ git cat-file -p af3....                            -p: show parent of given commit
· ·   tree 3212f923d36175b185cfa9dcc34ea068dc2a363c   ← Pointer to tree of interest
· ·   author    Alex Chan ... 1520806168 +0000        ← Context with author/commiter/
· ·   committer Alex Chan ... 1520806168 +0000          creation time/ ...
· ·   ...
· · "DEBUGGING" TIP: Use 'git cat-file -p 12d...' for pretty print ('-t' to display/debug object type)
· ·
· └ ~/.git/refs/heads/dev     ←  ~/.git/HEAD (pointer to active ref)
└·· ~/.git/refs/heads/master af3...  ← Create friendly "master" alias to a commit like:
                      ^^^^^^         $ $ git update-ref refs/heads/master   ← With plumbing each new commit requires a new
    refs in heads/ folder are        $ $ cat  .git/refs/heads/master          git update-ref.
    COMMONLY CALLED BRANCHS            af3... (pointer to commit)
                                       Now $ $ git cat-file -p master   "==" $ $ git cat-file -p af3...

                                     $ $ git rev-parse master               ← check value of ref
                                       af3...

                                     $ $ git update-ref refs/heads/dev     ← Create second branch (ref in heads/ folder)
                                     $ $ git branch
                                       dev
                                     * master ←·························  current branch is determined by (contents of)
                                     $ $ cat .git/HEAD                     ~/.git/HEAD. Using plumbing we can change it like
                                     ref: refs/heads/master                $ git symbolic-ref HEAD refs/heads/dev
<hr/>
<span title>merge/rebase/cherry-pick</span>
## REF:
@[https://stackoverflow.com/questions/9339429/what-does-cherry-picking-a-commit-with-git-mean]
@[https://git-scm.com/docs/git-cherry-pick]

 ┌ INITIAL STATE ──────────────────────────────────────────────────────────
 │ • → • → • → • →H1          ← refs/heads/branch01
 │         │
 │         └─→ •x1→ •x2→ •H2  ← refs/heads/branch02
 └────────────────────────────────────────────────────────────────────────
 ┌ MERGE @[https://git-scm.com/docs/git-merge]────────────────────────────
 │ add changes for other branch as single "M"erge commit
 │ $ $ git checkout branch01 && git merge branch02
 │ • → • → • → • → •H1 → •M  : M = changes of ( x1+x2+H2 )
 │         │             ↑
 │         └─→ •x1→ •x2→ •H2
 └────────────────────────────────────────────────────────────────────────
 ┌ REBASE @[https://git-scm.com/docs/git-rebase]──────────────────────────
 │ "replay" full list of commits to head of branch
 │ $ $ git checkout branch01 && git rebase branch02
 │ • → • → • → • →H1 •x1→ •x2→ •H2
 │         │
 │         └─→ •x1→ •x2→ •H2
 └────────────────────────────────────────────────────────────────────────
 ┌ Squash N last commit into single one  (rebase interactively) ──────────
 │
 │ • → • → • → • →H1      ← refs/heads/branch01
 │         │
 │         └─→ • H2' (x1 + x2)
 │
 │ $ $ git rebase --interactive HEAD~2

 │   pick 64d03e last-but-2 commit comment ← Different interesing actions are available
 │   pick 87718a last-but-1 commit comment   Replace "pick" by "s"(quash) to mark commit
 │   pick 83118f HEAD       commit comment   to be squashed into single commit.
 │                                            ·
 │   s 64d03e last-but-2 commit comment     ←·┘
 │   s 87718a last-but-1 commit comment     (Save and close editor. Git will combine all
 │   s 83118f HEAD       commit comment     commits into first in list)
 │                                          The editor will "pop up" again asking to enter
 │                                          a commit message.
 └────────────────────────────────────────────────────────────────────────

 ┌ CHERRY-PICK @[https://git-scm.com/docs/git-cherry-pick]────────────────
 │ "Pick" unique-commits from branch and apply to another branch
 │ $ $ git checkout branch02 && git cherry-pick  -x branch02
 │ ··· • → • →H1 → ...                          └┬┘
 │     │                  • Useful if "source" branch is public, generating
 │     └─→ • → • →H2 →      standardized commit message allowing co-workers
 │                          to still keep track of commit origin.
 │                        • Notes attached to the commit do NOT follow the
 │                          cherry-pick. Use $ $ git notes copy "from" "to"
 └────────────────────────────────────────────────────────────────────────
[[}]]

## GPG signed commits [[{security.secret_management,security.signed_content,01_PM.TODO.now]]
@[https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work]

  GPG PRESETUP

  See @[General/cryptography_map.html?id=pgp_summary] for a summary on
  how to generate and manage pgp keys.

  GIT PRESETUP
  $ git config --global \
        user.signingkey 0A46826A  ← STEP 1: Set default key for tags+commits sign.

  $ git tag -s v1.  -m 'my signed 1.5 tag'  ←   Signing tags
            └──┬──┘                           (follow instructions to sign)
          replaces -a/--anotate

  $ git show v1.5
  tag v1.5
  Tagger: ...
  Date:   ...

  my signed 1.5 tag
  -----BEGIN PGP SIGNATURE-----
  Version: GnuPG v1

  iQEcBAABAgAGBQJTZbQlAAoJEF0+sviABDDrZbQH/09PfE51KPVPlanr6q1v4/Ut
  ...
  =EFTF
  -----END PGP SIGNATURE-----

  commit ...

  $ git tag -  v1.4.2.1  ←   Verify tag
            └┘             Note: signer’s pub.key must be in local keyring
  object 883653babd8ee7ea23e6a5c392bb739348b1eb61
  type commit
  ...
  gpg: Signature made Wed Sep 13 02:08:25 2006 PDT using DSA key ID
  F3119B9A
  gpg: Good signature from "Junio C Hamano <junkio@cox.net>"
  gpg:                 aka "[jpeg image of size 1513]"
  Primary key fingerprint: 3565 2A26 2040 E066 C9A7  4A7D C0C6 D9A4
  F311 9B9A
  └──────────────────────────┬────────────────────────────────────┘
   Or error similar to next one will be displayed:
     gpg: Can't check signature: public key not found
   error: could not verify the tag 'v1.4.2.1'

  $ git commit -  -  -m 'Signed commit'  ←   Signing Commits (git 1.7.9+)

  $ git log --show-signature -1          ←   Verify Signatures
  commit 5c3386cf54bba0a33a32da706aa52bc0155503c2
  gpg: Signature made Wed Jun  4 19:49:17 2014 PDT using RSA key ID
  0A46826A
  gpg: Good signature from "1stName 2ndName (Git signing key)
  <user01@gmail.com>"
  Author: ...
  ...
$ $ git log --pretty="format:%h %G? %aN  %s"
                                ^^^
                                check and list found signatures
         Ex. Output:
    5c3386cG   1stName 2ndName  Signed commit
    ca82a6dR   1stName 2ndName  Change the version number
    085bb3bR   1stName 2ndName  Remove unnecessary test code
    a11bef0R   1stName 2ndName  Initial commit


You can also use the -S option with the git merge command to sign the
resulting merge commit itself. The following example both verifies
that every commit in the branch to be merged is signed and
furthermore signs the resulting merge commit.


$ git merge \             ←   # Verify signature at merge time
  --verify-signatures \
  -S \                    ← Sign merge itself.
  signed-branch-to-merge  ← Commit must have been signed.

$ git pull  \             ←   # Verify signature at pull time
  --verify-signatures
[[}]]

## Client Hooks [[{01_PM.TODO.now]]
@[https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks]

  Client-Side Hooks
  - not copied when you clone a repository
    - to enforce a policy do on the server side
  - committing-workflow hooks:
    - pre-commit hook:
      - First script to be executed.
      - used to inspect the snapshot that's about to be committed.
        - Check you’ve NOT forgotten something
        - make sure tests run
        - Exiting non-zero from this hook aborts the commit
      (can be bypassed with git commit --no-verify flag)
    - prepare-commit-msg hook:
      - Params:
        - commit_message_path (template for final commit message)
        - type of commit
        - commit SHA-1 (if this is an amended commit)
      - run before the commit message editor is fired up
        but after the default message is created.
      - It lets you edit the default message before the
        commit author sees it.
      - Used for non-normal-commits with auto-generated messages
        - templated commit messages
        - merge commits
        - squashed commits
        - amended commits
    - commit-msg hook:
        - commit_message_path (written by the developer)
    - post-commit hook:
      - (you can easily get the last commit by running git log -1 HEAD)
      - Generally, this script is used for notification or something similar.

  - email-workflow  hooks:
    - invoked by  git am
                  ^^^^^^
                  Apply a series of patches from a mailbox
                  prepared by git format-patch

    - applypatch-msg :
      - Params:
        - temp_file_path containing the proposed commit message.
    - pre-applypatch :
      - confusingly, it is run after the patch is
        applied but before a commit is made.
      - can be used it to inspect the snapshot before making the commit,
        run tests,  inspect the working tree with this script.
    - post-applypatch :
      - runs after the commit is made.
      - Useful to notify a group or the author of the patch
        you pulled in that you’ve done so.

  - Others:
    - pre-rebase hook:
      - runs before you rebase anything
      - Can be used to disallow rebasing any commits
        that have already been pushed.
    - post-rewrite hook:
      - Params:
        - command_that_triggered_the_rewrite:
          - It receives a list of rewrites on stdin.
      - run by commands that replace commits
        such as 'git commit --amend' and 'git rebase'
        (though not by git filter-branch).
      - This hook has many of the same uses as the
        post-checkout and post-merge hooks.
    - post-checkout hook:
      - Runs after successful checkout
      - you can use it to set up your working directory
        properly for your project environment.
        This may mean moving in large binary files that
        you don't want source controlled, auto-generating
        documentation, or something along those lines.
    - post-merge hook:
      - runs after a successful merge command.
      - You can use it to restore data in the working tree
        that Git can't track, such as permissions data.
        It can likewise validate the presence of files
        external to Git control that you may want copied
        in when the working tree changes.
    - pre-push hook:
      - runs during git push, after the remote refs
        have been updated but before any objects have
        been transferred.
      - It receives the name and location of the remote
        as parameters, and a list of to-be-updated refs
        through stdin.
      - You can use it to validate a set of ref updates before
        a push occurs (a non-zero exit code will abort the push).
[[}]]

## Server-Side Hooks [[{01_PM.TODO.now]]
(system administrator only)
- Useful to enforce nearly any kind of policy in repository.

- exit non-zero to rollback/reject push
  and print error message back to the client.

 pre-receive hook :
 - first script to run
 - INPUT: STDIN reference list
 - Rollback all references on non-zero exit

 - Ex.
   - Ensure none of the updated references are non-fast-forwards.
   - do access control for all the refs and files being modifying
     by the push.

 update hook :
 - similar to pre-receive hook.but  run once for each branch the
   push is trying to update  (ussually just one branch is updated)

 - INPUT arguments:
   - reference name (for branch),
   - SHA-1
   - SHA-1
     refname= ARGV[0] ← ref.name for current branch
     oldrev = ARGV[1] ←  (SHA-1)  original (current-in-server)      ref. *1
     newrev = ARGV[2] ←  (SHA-1)  new      (intention to)      push ref. *1
     user   = $USER   ← "Injected" by git when using ssh.

     *1: We can run over all commit from $oldrev to $newrev like
         git rev-list \                        ← display a (sha1)commit per line to STDOUT
             oldrev..$newrev \                 ← from $oldrev to $newrev
             while read SHA_COMMIT ; do
            git cat-file commit $SHA_COMMIT \  ← *1
            | sed '1,/^$/d'                    ← Delete from line 1 to first match of
                                                 empty-line (^$).



  *1 output format is similar to:
  | tree      ...
  | parent    ...
  | committer ...
  |
  | My commit Message
  | tree      ...

  - user-name (if accesing through ssh) based on ssh public-key.
 - Exit  0: Update
   Exit !0: Rollback reference, continue with next one.

 post-receive
 - can be used to update other services or notify users.
 - INPUT: STDIN reference list
 - Useful for:
   - emailing a list.
   - trigger CI/CD.
   - update ticket system
     (commit messages can be parsed for "open/closed/..."
 -   WARN : can't stop the push process.
   client  will block until completion.
[[}]]

## GIT Commit Standard Emojis: [[{]]
@[https://gist.github.com/parmentf/035de27d6ed1dce0b36a]
 Commit type               Emoji                    Graph
 Initial commit           :tada:                      🎉
 Version tag              :bookmark:                  🔖
 New feature              :sparkles:                  ✨
 Bugfix                   :bug:                       🐛
 Metadata                 :card_index:                📇
 Documentation            :books:                     📚
 Documenting src          :bulb:                      💡
 Performance              :racehorse:                 🐎
 Cosmetic                 :lipstick:                  💄
 Tests                    :rotating_light:            🚨
 Adding a test            :white_check_mark:          ✅
 Make a test pass        :heavy_check_mark:           ✔️
 General update           :zap:                       ⚡️
 Improve format           :art:                       🎨
 /structure
 Refactor code            :hammer:                    🔨
 Removing stuff           :fire:                      🔥
 CI                       :green_heart:               💚
 Security                 :lock:                      🔒
 Upgrading deps.         :arrow_up:                   ⬆️
 Downgrad. deps.         :arrow_down:                 ⬇️
 Lint                     :shirt:                     👕
 Translation              :alien:                     👽
 Text                     :pencil:                    📝
 Critical hotfix          :ambulance:                 🚑
 Deploying stuff          :rocket:                    🚀
 Work in progress         :construction:              🚧
 Adding CI build system   :construction_worker:       👷
 Analytics|tracking code  :chart_with_upwards_trend:  📈
 Removing a dependency    :heavy_minus_sign:          ➖
 Adding a dependency      :heavy_plus_sign:           ➕
 Docker                   :whale:                     🐳
 Configuration files      :wrench:                    🔧
 Package.json in JS       :package:                   📦
 Merging branches         :twisted_rightwards_arrows: 🔀
 Bad code / need improv.  :hankey:                    💩
 Reverting changes        :rewind:                    ⏪
 Breaking changes         :boom:                      💥
 Code review changes      :ok_hand:                   👌
 Accessibility            :wheelchair:                ♿️
 Move/rename repository  :truck:                      🚚
[[}]]

## GitHub Custom Bug/Feat-req templates [[{git.github]]
  WARN : Non standard (Vendor lock-in) Microsoft extension.
 $ cat .github/ISSUE_TEMPLATE/bug_report.md
 | ---
 | name: Bug report
 | about: Create a report to help us improve
 | title: ''
 | labels: ''
 | assignees: ''
 |
 | ---
 |
 | **Describe the bug**
 | A clear and concise description of what the bug is.
 |
 | **To Reproduce**
 | Steps to reproduce the behavior:
 | 1. Go to '...'
 | 2. Click on '....'
 | 3. Scroll down to '....'
 | 4. See error
 |
 | **Expected behavior**
 | A clear and concise description of what you expected to happen.
 |
 | ...

 $ cat .github/ISSUE_TEMPLATE/feature_request.md
  | ---
  | name: Feature request
  | about: Suggest an idea for this project
  | title: ''
  | labels: ''
  | assignees: ''
  |
  | ---
  |
  | **Is your feature request related to a problem? Please describe.**
  | A clear and concise description of what the problem is....
  |
  | **Describe the solution you'd like**
  | A clear and concise description of what you want to happen.
  |
  | **Describe alternatives you've considered**
  | A clear and concise description of any alternative solutions or features you've considered.
  |
  | **Additional context**
  | Add any other context or screenshots about the feature request here.

 $ cat ./.github/pull_request_template.md
 ...

 $ ./.github/workflows/*
  WARN : Non standard (Vendor lock-in) Microsoft extension.
 @[https://docs.github.com/en/free-pro-team@latest/actions/learn-github-actions]
[[}]]

## Unbreakable Branches: [[{git.bitbucket,qa,jenkins.troubleshooting]]
@[https://github.com/AmadeusITGroup/unbreakable-branches-jenkins]

- plugins for Bitbucket and Jenkins trying to fix next problem:

  Normal Pull Request workflow:
  Open pull-request (PR) to merge changes in target-branch
    → (build automatically triggered)
      → build OK
        repo.owner merges PR
         → second build triggered on target-branch
           →  second build randomnly fails
              leading to broken targeted branch
              └───────────────┬───────────────┘
               Reasons include:
               - Race condition: Parallel PR was merged in-between
               - Environment issue (must never happens)
               - lenient dependency declaration got another version
                 leading to a build break

  - If the Jenkins job is eligible to unbreakable build
    (by having environment variables such as UB_BRANCH_REF)
    at the end of the build a notification to Bitbucket is
    sent according to the build status.
    (or  manually through two verbs: ubValidate|ubFail)

- Difference stashnotifier-plugin:
  - stashplugin reports status-on-a-commit
  - unbreakable build a different API is dedicated on Bitbucket.

- On the Bitbucket side:
  - GIT HEAD@target-branch moved to  top-of-code to be validated in PR
    (target-branch can then always have a successful build status).

- Security restrictions added to Bitbucket:
  (once you activate the unbreakable build on a branch for your repository)
  -  merge button replaced by merge-request-button to queue the build.
  -  The merge will happen automatically at the end of the build if the build succeeds
  -  direct push on the branch is forbidden
  -  Merge requests on different PRs will process the builds sequentially

- Prerequisites to run the code locally:
  - Maven (tested agains 3.5)
  - Git should be installed

- PRE-SETUP:
  - Install UnbreakableBranch plugin at Bitbucket
  - bitbucketBranch source plugin Jenkins plugin should be
    a patched so that mandatory environment variables are
    injected.   Note that this plugin hasn't been released yet


@[https://github.com/newren/git-filter-repo/]
- Create new repository from old ones, keeping just the
  history of a given subset of directories.

(Replace: (buggy)filter-branch @[https://git-scm.com/docs/git-filter-branch])
- Python script for rewriting history:
  - cli for simple use cases.
  - library for writing complex tools.

- Presetup:
  - git 2.22.0+  (2.24.0+ for some features)
  - python 3.5+

  $ git filter-repo \
       --path src/ \                         ← commits not touching src/ removed
       --to-subdirectory-filter my-module \  ← rename  src/** → my-module/src/**
       --tag-rename '':'my-module-'            add 'my-module-' prefix to any tags
                                               (avoid any conflicts later merging
                                                into something else)

  Design rationale behind filter-repo :
  - None existing tools with similr features.
  - [Starting report] Provide analysis before pruning/renaming.
  - [Keep vs. remove] Do not just allow to remove selected paths
                      but to keep certain ones.
    (removing all paths except a subset can be painful.
     We need to specify all paths that ever existed in
     any version of the repository)
  - [Renaming] It should be easy to rename paths:
  - [More intelligent safety].
  - [Auto shrink] Automatically remove old cruft and repack the
    repository for the user after filtering (unless overridden);
  - [Clean separation] Avoid confusing users (and prevent accidental
    re-pushing of old stuff) due to mixing old repo and rewritten repo
    together.
  - [Versatility] Provide the user the ability to extend the tool
    ... rich data structures (vs hashes, dicts, lists, and arrays
        difficult to manage in shell)
    ... reasonable string manipulation capabilities
  - [Old commit references] Provide a way for users to use old commit
    IDs with the new repository.
  - [Commit message consistency] Rewrite commit messages pointing to other
    commits by ID.
  - [Become-empty pruning] empty commits should be pruned.
  - [Speed]

- Work on filter-repo and predecessor has driven
  improvements to fast-export|import (and occasionally other
  commands) in core git, based on things filter-repo needs to do its
  work:

  Manual Summary :
@[https://htmlpreview.github.io/?https://github.com/newren/git-filter-repo/blob/docs/html/git-filter-repo.html]
- Overwrite entire repository history using user-specified filters.
  (WARN: deletes original history)
  - Use cases:
    - stripping large files (or large directories or large extensions)
    - stripping unwanted files by path (sensitive secrests) [secret]
    - Keep just an interesting subset of paths, remove anything else.
    - restructuring file layout. Ex:
      - move all files subdirectory
      - making subdirectory as new toplevel.
      - Merging two directories with independent filenames.
      - ...
    - renaming tags
    - making mailmap rewriting of user names or emails permanent
    - making grafts or replacement refs permanent
    - rewriting commit messages
[[}]]

## What's new [[{]]
### 2.40
  https://www.infoq.com/news/2023/04/git-releases-version-2-40/

## Git 2.37 Brings Built-in File Monitor, Improved Pruning, and More
  https://www.infoq.com/news/2022/06/git-2-37-released/ 
  According to Jeff Hostetler, the author of the patches for git's new
  file monitor, the implementation relies mostly on cross-platform code
  with custom backends leveraging OS-native features, i.e. FSEvents on
  macOS and ReadDirectoryChangesW on Windows. A Linux backend would
  probably use either inotify or fanotify, Hostetler says, but that
  work has not started yet.

### 2.35 [[{]]
  SSH signing you to use SSH-keys to sign certain kinds of objects in Git.
  - Git 2.35 includes a couple of new additions to SSH signing.
    -  To track which SSH keys you trust, you use the ALLOWED SIGNERS FILE
       to store the identities and public keys of signers you trust.
       PROBLEM: NOW suppose one commiter rotates their key.
       - You could update their entry in the allowed signers file
         but that would make it impossible to validate objects signed with
         the older key.
       - You could store both keys, but that would mean that you
         would accept new objects signed with the old key.
       SOLUTION: Git 2.35 lets you take advantage of OpenSSH’s
                 valid-before and valid-after directives.
   - Git 2.35 also supports new key types in the user.signingKey
     configuration when you include the key verbatim (instead of storing
     the path of a file that contains the signing key). Previously, the
     rule for interpreting user.signingKey was to treat its value as a
     literal SSH key if it began with “ssh-“, and to treat it as
     filepath otherwise. You can now specify literal SSH keys with
     keytypes that don’t begin with “ssh-” (like ECDSA
     keys).[source, source]
[[}]]

[[}]]


[[}]]



# Git TODO [[{01_PM.TODO]]
## GitOps Git as single source of truth
  for declarative infrastructure and [[{ci/cd.gitops]]
  applications. Every developer within a team can issue pull requests against a
  Git repository, and when merged, a "diff and sync" tool detects a difference
  between the intended and actual state of the system. Tooling can then be
  triggered to update and synchronise the infrastructure to the intended state.
 @[https://www.weave.works/blog/gitops-operations-by-pull-request]             [[}]]

## Scalar (Git v2.38+) [[{git.scalability,scalability.storage]]
@[https://git-scm.com/docs/scalar]
* Replace previous Git LFS/VFS support for "big files and repositories
  with a native Git integration.

* Scalar improves performance by configuring advanced Git settings,
 maintaining repositories in the background, and helping to reduce
 data sent across the network.


@[https://github.blog/2022-10-13-the-story-of-scalar/]
[[}]]

## NostrGit [[{git.nostr]]
@[https://github.com/NostrGit/NostrGit]

 A truly censorship-resistant alternative to GitHub that has a chance of working
[[}]]



## 4 secrets encryption tools [[{security.secret_management}]]
@[https://www.linuxtoday.com/security/4-secrets-management-tools-for-git-encryption-190219145031.html]
@[https://www.atareao.es/como/cifrado-de-repositorios-git/]

## Garbage Collector [[{performance]]
-  Git occasionally does garbage collection as part of its normal operation,
by invoking git gc --auto. The pre-auto-gc hook is invoked just before the
garbage collection takes place, and can be used to notify you that this is
happening, or to abort the collection if now isn’t a good time.
[[}]]


## sparse-checkout (Git v2.25+) allows to checkout just a subset [[{scalability]]
  of a given monorepo, speeding up commands like git pull and
  git status.
@[https://github.blog/2020-01-17-bring-your-monorepo-down-to-size-with-sparse-checkout/] [[}]]

## Advanced Git:
  - revert/rerere:
  - Submodules:
  - Subtrees:
    - TODO: how subtrees differ from submodules
    - how to use the subtree to create a new project from split content
  - Interactive rebase:
    - how to rebase functionality to alter commits in various ways.
    - how to squash multiple commits down into one.
  - Supporting files:
    - Git attributes file and how it can be used to identify binary files,
      specify line endings for file types, implement custom filters, and
      have Git ignore specific file paths during merging.
  - Cregit token level blame:
  @[https://www.linux.com/blog/2018/11/cregit-token-level-blame-information-linux-kernel]
  cregit: Token-Level Blame Information for the Linux Kernel
  Blame tracks lines not tokens, cgregit blames on tokens (inside a line)

## Gitea painless self-hosted Git ) [[{01_PM.TODO,01_PM.low_code]]
("replaced" unmaitained Gogs)
@[https://gitea.io/]
- Fork of gogs, since it was unmaintained.

## Gerrit (by Google)</span>
@[https://www.gerritcodereview.com/index.html]
Gerrit is a Git Server that provides:
- Code Review:
  - One dev. writes code, another one is asked to review it.
    (Goal is cooperation, not fauilt-finding)
  @[https://docs.google.com/presentation/d/1C73UgQdzZDw0gzpaEqIC6SPujZJhqamyqO1XOHjH-uk/]
  - UI for seing changes.
  - Voting pannel.


- Access Control on the Git Repositories.
- Extensibility through Java plugins.
@[https://www.gerritcodereview.com/plugins.html]


Gerrit does NOT provide:
- Code Browsing
- Code SEarch
- Project Wiki
- Issue Tracking
- Continuous Build
- Code Analyzers
- Style Checkers
[[}]]

## Git Secrets: [[{qa,security.secret_management}]]
https://github.com/awslabs/git-secrets#synopsis
- Prevents you from committing passwords and other sensitive
  information to a git repository.

## Forgit: Interactive Fuzzy Finder:[[{dev_stack.forgit,qa.UX,01_PM.TODO]]
@[https://www.linuxuprising.com/2019/11/forgit-interactive-git-commands-with.html]
- It takes advantage of the popular "fzf" fuzzy finder to provide
  interactive git commands, with previews. [[}]]

## Isomorphic Git: 100% JS client [[{security.gpg]]
@[https://isomorphic-git.org/] !!!

- Features:
  - clone repos
  - init new repos
  - list branches and tags
  - list commit history
  - checkout branches
  - push branches to remotes
  - create new commits
  - git config
  - read+write raw git objects
  - PGP (GPG) signing
  - file status
  - merge branches
[[}]]

## Git Monorepos: [[{qa.UX]]
  (Big) Monorepos in Git:
  https://www.infoq.com/presentations/monorepos/
  https://www.atlassian.com/git/tutorials/big-repositories [[}]]


## Git: Symbolic Ref best-patterns
@[https://stackoverflow.com/questions/4986000/whats-the-recommended-usage-of-a-git-symbolic-reference]

## GitHub: Search by topic: [[{git.github}]]
  https://help.github.com/en/github/searching-for-information-on-github/searching-topics
  Ex:search by topic ex "troubleshooting" and language "java"
  https://github.com/topics/troubleshooting?l=java


## Gitsec: [[{security.secret_management,qa]]
  @[https://github.com/BBVA/gitsec]
  gitsec is an automated secret discovery service for git that helps
  you detect sensitive data leaks.
  gitsec doesn't directly detect sensitive data but uses already
  available open source tools with this purpose and provides a
  framework to run them as one.
[[}]]

[[}]]
[[git}]]

# Networking Summary for DevOps [[{networking.101,01_PM.low_code,networking.load_balancer,web_balancer]]

## HTTP balanced proxy Quick Setup with HAProxy [[{]]
  REF: @[https://github.com/AKSarav/haproxy-nodejs-redis/blob/master/haproxy/]
  ┌──haproxy/haproxy.cfg ────────────  ┌ haproxy/Dockerfile ──────────────────────────
  │ global                             │ FROM haproxy
  │   daemon                           │ COPY haproxy.cfg /usr/local/etc/haproxy/haproxy.cfg
  │   maxconn 256                      └──────────────────────────────────────────────
  │
  │ defaults
  │   mode http
  │   timeout connect 5000ms
  │   timeout client 50000ms
  │   timeout server 50000ms
  │
  │ frontend http-in
  │   bind *:80                             <·· Listen on port 80 on all interfaces
  │   default_backend servers
  │
  │ backend servers                         <·· Forward to single backend "servers"
  │   server server1 host01:8081 maxconn 32 <·· composed of (single server) "server1"
  │                                             at host01:8081
  └─────────────────────────────────────────
## Reverse Proxy  [[01_PM.TODO]]
## Forward Proxy  [[01_PM.TODO]]
[[}]]

## CharlesProxy: Monitor TLS/HTTPS traffic [[{networking.TLS,troubleshooting,01_PM.TODO]]
@[https://www.charlesproxy.com/]
  HTTP proxy / HTTP monitor / Reverse Proxy enabling developers to view HTTP+SSL/HTTPS
  traffic between loal machine and Internet, including requests, responses and HTTP headers
  (which contain the cookies and caching information).
  [[}]]

## DNS Records [[{]]
  ┌ DNS Records ────────────────────────────────┐
  │ A       root domain name IP address         │
  │         Ex: mydomain.com → 1.2.3.4          │
  │         Not recomended for changing IPs     │
  ├─────────────────────────────────────────────┤
  │ CNAME   maps name2 → name1                  │
  │         Ex: int.mydomain.com → mydomain.com │
  ├─────────────────────────────────────────────┤
  │ Alias   Amazon Route 53 virtual record      │
  │         to map AWS resources like ELBs,     │
  │         CloudFront, S3 buckets, ...         │
  ├─────────────────────────────────────────────┤
  │ MX      mail server name → IP address       │
  │         Ex: smtp.mydomain.com → 1.2.3.4     │
  ├─────────────────────────────────────────────┤
  │ AAAA    A record for IPv6 addresses         │
  └─────────────────────────────────────────────┘
[[}]]

## SERVICE MESH EVOLUTION  [[{01_PM.low_code]]

  Summary extracted from @[https://isovalent.com/blog/post/2021-12-08-ebpf-servicemesh]
                         @[https://www.infoq.com/news/2022/01/ebpf-wasm-service-mesh/]

  Service Mesh: Takes care of (netwok)distributed concerns (visibility, security, balancing,
                service discovery, ...)

  1st GENERATION. Each app     2nd Generation. A common      3rd Generation. Sidecar
  links against a library.     sidecar is used.              functionality moved to
                                                             linux kernel usinb eBFP
  ┌─ App1 ────┐ ┌─ App2 ────┐  ┌─ App1 ────┐ ┌─ App2 ────┐
  │  ┌───────┐│ │  ┌───────┐│  │           │ │           │
  │  │Service││ │  │Service││  └───────────┘ └───────────┘   ┌─ App1 ────┐ ┌─ App2 ────┐
  │  │Mesh   ││ │  │Mesh   ││  ┌───────────┐ ┌───────────┐   │           │ │           │
  │  │Library││ │  │Library││  │ServiceMesh│ │ServiceMesh│   └───────────┘ └───────────┘
  │  └───────┘│ │  └───────┘│  │SideCar    │ │SideCar    │   ┌─ Kernel ────────────────┐
  └───────────┘ └───────────┘  └───────────┘ └───────────┘   │ ┌─ eBFP Service Mesh ┐  │
  ┌─ Kernel ────────────────┐  ┌─ Kernel ────────────────┐   │ └────────────────────┘  │
  │       ┌─ TCP/IP ─┐      │  │       ┌─ TCP/IP ─┐      │   │       ┌─ TCP/IP ─┐      │
  │       └──────────┘      │  │       └──────────┘      │   │       └──────────┘      │
  │       ┌─ Network─┐      │  │       ┌─ Network─┐      │   │       ┌─ Network─┐      │
  │       └──────────┘      │  │       └──────────┘      │   │       └──────────┘      │
  └─────────────────────────┘  └─────────────────────────┘   └─────────────────────────┘
                                 Envoy, Linkerd, Nginx,...     Cilium
                                 or kube-proxy

   App1 ←→ Kernel TCP/IP        App1 ←→ SideCar1              App1 ←→ Kernel eBFP
   Kernel TCP/IP ←→ App2        SideCar1 ←→ Kernel TCP/IP     Kernel eBFP ←→ App2
                                Kernel TCP/IP ←→ Sidecar2
                                Sidecar2 ←→ App2
   [[}]]

[[networking.101}]]

# Monitoring for DevOps 101 [[{monitoring.101,]]

## Infra vs App Monitoring [[{02_doc_has.comparative]]
### *Infrastructure Monitoring*
   · Prometheus + Grafana (Opinionated)
     Prometheus periodically pulls multidimensional data from different apps/components.
     Grafana allows to visualize Prometheus data in custom dashboards.
     (Alternatives include Monit, Datadog, Nagios, Zabbix, ...)

### *Application Monitoring*
   · OpenTelemetry: replaces OpenTracing and OpenCensus.
     Cloud Native Foundation projects.
     It also serves as ¿front-end? for Jaeger and others.
   · Jaeger, New Relic: (Very opinionated)
   (Other alternatives include AppDynamics, Instana, ...)

### *Log Management* (Opinionated)
   · Elastic Stack
     (Alternative include Graylog, Splunk, Papertrail, ...)
     Elastic search has evolved throught the years to become a
     full analytical platform.

* MUCH MORE DETAILED INFORMATION IS AVAILABLE AT:
 @[../../txt_world_domination/viewer.html?payload=../SoftwareArchitecture/ddbb_engines.txt]

[[}]]
[[monitoring.101}]]

# Non-Classified/TODO/Backlog [[{01_PM.TODO]]

## Yaml References [[{yaml.101]]
@[http://docs.ansible.com/ansible/YAMLSyntax.html]

  ```
  YAML                               JSON
  ---                                {
  key1: val1                             "key1": "val1",
  key2:                                 "key2": [
   - "thing1"                            "thing1",
   - "thing2"                            "thing2"
  # I am a comment                     ]
                                   }
  ```

- Anchors allows to reuse/extends YAML code:
  ┌─ YAML ───────────┐···(generates)··>┌─ JSON ────────────────┐
  │ ---              │                 │                       │
  │ key1: &anchor    ← '&' Defines     │ {                     │
  │  K1: "One"       │ the anchor      │   "key1": {           │
  │  K2: "Two"       │                 │     "K1": "One",      │
  │                  │                 │     "K2": "Two"       │
  │                  │                 │   },                  │
  │ key2: *anchor    ← References/     │   "key2": {           │
  │                  │ uses the anch.  │     "K1": "One",      │
  │                  │                 │     "K2": "Two"       │
  │                  │                 │   }                   │
  │ key3:            │                 │   "key3": {           │
  │   <<: *anchor    ← Extends anch.   │     "K1": "One",      │
  │   K2: "I Changed"│                 │     "K2": "I Changed",│
  │                  │                 │     "K3": "Three"     │
  │                  │                 │   }                   │
  │   K3: "Three"    │                 │                       │
  │                  │                 │ }                     │
  └──────────────────┘                 └───────────────────────┘
  WARN!!!: Many NodeJS parsers break the 'extend' functionality.

- Extend Inline:
  - take only SOME sub-keys from key1 to inject into key2
  ┌─ YAML ──────     ┐···(generates)··>┌─ JSON ───────────┐
  │ ---              │                 │ {                │
  │ key1:            │                 │   "key1": {      │
  │  <<: &anchor     ← Inject into     │     "K1": "One", │
  │    K1: "One"     │ key1 and save   │     "K2": "Two"  │
  │  K2: "Two"       │ as anchor       │   },             │
  │                  │                 │                  │
  │ bar:             │                 │   "bar": {       │
  │  <<: *anchor     │                 │     "K1": "One", │
  │  K3: "Three"     │                 │     "K3": "Three"│
  │                  │                 │   }              │
  │                  │                 │ }                │
  └──────────────────┘                 └──────────────────┘

- yaml2js python Ulitity:
  - Add next lines to ~/.bashrc (or /etc/profile or ...):
  + alias yaml2js="python -c 'import sys, yaml, json; \
  +                json.dump(yaml.load(sys.stdin), sys.stdout, indent=4)'"

  Ussage:
  $ cat in.yaml | yaml2js > out.json

 *WARN:* - Unfortunatelly there is no way to override or
           extends lists to append new elements to existing ones,
           only maps/dictionaries with the '<<' operator:
           '<<' "inserts" values of referenced map into
           current one being defined.
[[}]]

# Source{d}: Large Scale Code Analysis with IA [[{security,qa.code_analysis,qa.testing,git,01_PM.TODO]]
@[https://www.linux.com/blog/holberton/2018/10/sourced-engine-simple-elegant-way-analyze-your-code]

- source{d} offers a suite of applications that uses machine learning on code
  to complete source code analysis and assisted code reviews. Chief among them
  is the source{d} Engine, now in public beta; it uses a suite of open source
  tools (such as Gitbase, Babelfish, and Enry) to enable large-scale source
  code analysis. Some key uses of the source{d} Engine include language
  identification, parsing code into abstract syntax trees, and performing SQL
  Queries on your source code such as:
    - What are the top repositories in a codebase based on number of commits?
    - What is the most recent commit message in a given repository?
    - Who are the most prolific contributors in a repository
[[}]]


[[}]]
